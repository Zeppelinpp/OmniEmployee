# BIEM è®°å¿†ç³»ç»ŸæŠ€æœ¯æ–‡æ¡£

> **Bio-Inspired Evolving Memory (BIEM)** â€” ä¸€ä¸ªä»¿ç”Ÿå­¦å¯å‘çš„å¤šå±‚çº§è®°å¿†ç³»ç»Ÿ

---

## ç³»ç»Ÿæ¦‚è¿°

BIEM æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿäººç±»è®°å¿†æœºåˆ¶çš„å¤šå±‚çº§è®°å¿†ç³»ç»Ÿï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š

- **èƒ½é‡è¡°å‡**ï¼šè®°å¿†éšæ—¶é—´è‡ªç„¶é—å¿˜ï¼Œé¢‘ç¹è®¿é—®çš„è®°å¿†ä¿æŒæ´»è·ƒ
- **å…³è”æ¿€æ´»**ï¼šé€šè¿‡å›¾ç»“æ„å®ç°è®°å¿†é—´çš„è”æƒ³ä¼ æ’­
- **å†²çªæ£€æµ‹**ï¼šè¯†åˆ«æ–°æ—§ä¿¡æ¯ä¹‹é—´çš„è®¤çŸ¥å¤±è°ƒ
- **å±‚çº§æµåŠ¨**ï¼šè®°å¿†åœ¨ä¸åŒå±‚çº§é—´æ ¹æ®"çƒ­åº¦"è‡ªåŠ¨å‡é™
- **çŸ¥è¯†å­¦ä¹ **ï¼šä»å¯¹è¯ä¸­æŠ½å–ç»“æ„åŒ–ä¸‰å…ƒç»„çŸ¥è¯†ï¼Œæ”¯æŒæ›´æ–°å’Œå†²çªæ£€æµ‹

### ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```mermaid
graph TB
subgraph "Agent Runtime"
  USER[ç”¨æˆ·è¾“å…¥] --> PLUGIN[BIEMContextPlugin]
  PLUGIN --> MM[MemoryManager]
  USER --> KL[KnowledgeLearningPlugin]
  MM --> CONTEXT[Context æ³¨å…¥]
  KL --> CONTEXT
  CONTEXT --> LLM[LLM è°ƒç”¨]
  LLM --> RESPONSE[å“åº”è¾“å‡º]
  RESPONSE --> RECORD[è®°å½•åˆ°è®°å¿†]
end
subgraph "Memory Tiers"
  MM --> L1[L1 Working Canvas<br/>Python Dict]
  MM --> L2V[L2 Vector Storage<br/>Milvus]
  MM --> L2G[L2 Graph Storage<br/>NetworkX]
  MM --> L3[L3 Crystal<br/>PostgreSQL]
end
subgraph "Knowledge Storage"
  KL --> KPG[(PostgreSQL<br/>knowledge_triples)]
  KL --> KMV[(Milvus<br/>biem_knowledge)]
end
subgraph "Operators"
  MM --> ENC[Encoder<br/>Ollama BGE-M3]
  MM --> ENERGY[EnergyController]
  MM --> ROUTER[AssociationRouter]
  MM --> CONFLICT[ConflictChecker]
end
style L1 fill:#ff6b6b,color:#fff
style L2V fill:#4ecdc4,color:#fff
style L2G fill:#45b7d1,color:#fff
style L3 fill:#96ceb4,color:#fff
style KPG fill:#96ceb4,color:#fff
style KMV fill:#4ecdc4,color:#fff
```

---

## ä¸‰å±‚è®°å¿†æ¶æ„

### å±‚çº§æ¦‚å¿µå¯¹æ¯”

| å±‚çº§ | åç§° | ç±»æ¯” | å­˜å‚¨ä»‹è´¨ | ç‰¹ç‚¹ |
|------|------|------|----------|------|
| **L1** | Working Canvas | å·¥ä½œè®°å¿† | Python Dict | é«˜é€Ÿã€æ˜“å¤±ã€å®¹é‡å° |
| **L2** | Association Web | é•¿æœŸè®°å¿† | Milvus + NetworkX | å‘é‡æ£€ç´¢ + å›¾å…³è” |
| **L3** | The Crystal | ç»“æ™¶çŸ¥è¯† | PostgreSQL | æŒä¹…åŒ–äº‹å®ä¸é“¾æ¥ |

### L1 - Working Canvasï¼ˆå·¥ä½œç”»å¸ƒï¼‰

```mermaid
graph LR
subgraph "L1 Working Memory"
  direction TB
  N1[Node A<br/>E=0.95]
  N2[Node B<br/>E=0.82]
  N3[Node C<br/>E=0.71]
  N4[Node D<br/>E=0.58]
  EVICT[...ä½èƒ½é‡èŠ‚ç‚¹è¢«é©±é€]
end
NEW[æ–°é«˜èƒ½é‡èŠ‚ç‚¹] -->|èƒ½é‡ â‰¥ 0.5| N1
N4 -->|èƒ½é‡ < 0.3| DEMOTE[é™çº§åˆ° L2]
style N1 fill:#ff6b6b
style N2 fill:#ff8585
style N3 fill:#ffa0a0
style N4 fill:#ffbaba
```

**èŒè´£**ï¼š
- å­˜å‚¨å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„é«˜èƒ½é‡èŠ‚ç‚¹
- å®¹é‡é™åˆ¶ï¼ˆé»˜è®¤ 100 èŠ‚ç‚¹ï¼‰ï¼Œè¶…é™æ—¶é©±é€ä½èƒ½é‡èŠ‚ç‚¹
- æä¾›æœ€å¿«çš„è®¿é—®é€Ÿåº¦

**é…ç½®å‚æ•°**ï¼š
```python
@dataclass
class L1Config:
  max_nodes: int = 100       # æœ€å¤§å®¹é‡
  ttl_seconds: float = 3600  # éæ´»è·ƒè¶…æ—¶ (1å°æ—¶)
  min_energy: float = 0.1    # æœ€ä½èƒ½é‡é˜ˆå€¼
```

### L2 - Association Webï¼ˆå…³è”ç½‘ç»œï¼‰

L2 ç”±ä¸¤ä¸ªå­ç³»ç»Ÿç»„æˆï¼š

```mermaid
graph TB
subgraph "L2 Association Web"
  subgraph "Vector Storage (Milvus)"
    V1[èŠ‚ç‚¹å‘é‡<br/>1024ç»´]
    V2[å…ƒæ•°æ®ç´¢å¼•]
    V3[ç›¸ä¼¼åº¦æ£€ç´¢]
  end
  subgraph "Graph Storage (NetworkX)"
    G1((A)) -->|temporal| G2((B))
    G2 -->|semantic| G3((C))
    G1 -->|causal| G3
    G3 -->|temporal| G4((D))
  end
end
QUERY[æŸ¥è¯¢å‘é‡] --> V3
V3 --> SEEDS[ç§å­èŠ‚ç‚¹]
SEEDS --> G1
G1 -->|ä¼ æ’­æ¿€æ´»| EXPAND[æ‰©å±•å¬å›]
```

#### L2-Vector (Milvus)

**èŒè´£**ï¼š
- å­˜å‚¨æ‰€æœ‰è®°å¿†èŠ‚ç‚¹çš„å‘é‡åµŒå…¥
- æ”¯æŒé«˜æ•ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
- æ ‡é‡å­—æ®µè¿‡æ»¤ï¼ˆèƒ½é‡ã€æ—¶é—´æˆ³ã€æƒ…æ„Ÿç­‰ï¼‰

**æ•°æ®æ¨¡å¼**ï¼š
```sql
-- Milvus Collection Schema
id VARCHAR(64) PRIMARY KEY        -- UUID
content VARCHAR(65535)           -- åŸæ–‡å†…å®¹
vector FLOAT_VECTOR(1024)        -- BGE-M3 åµŒå…¥
energy FLOAT                     -- èƒ½é‡å€¼ [0,1]
timestamp INT64                  -- åˆ›å»ºæ—¶é—´æˆ³
last_accessed INT64              -- æœ€åè®¿é—®æ—¶é—´
tier VARCHAR(8)                  -- å½“å‰å±‚çº§
sentiment FLOAT                  -- æƒ…æ„Ÿææ€§ [-1,1]
```

#### L2-Graph (NetworkX)

**èŒè´£**ï¼š
- ç»´æŠ¤èŠ‚ç‚¹é—´çš„å…³è”å…³ç³»
- æ”¯æŒä¼ æ’­æ¿€æ´»ï¼ˆSpreading Activationï¼‰å¬å›
- ä¸‰ç§é“¾æ¥ç±»å‹ï¼štemporalã€semanticã€causal

**é“¾æ¥ç±»å‹**ï¼š
```python
class LinkType(Enum):
  TEMPORAL = "temporal"  # æ—¶åºå…³ç³»ï¼ˆåŒä¸€å¯¹è¯/æ—¶é—´çª—å£ï¼‰
  SEMANTIC = "semantic"  # è¯­ä¹‰ç›¸ä¼¼ï¼ˆå‘é‡ç›¸ä¼¼åº¦ > 0.7ï¼‰
  CAUSAL = "causal"      # å› æœå…³ç³»ï¼ˆåé¦ˆå­¦ä¹ å»ºç«‹ï¼‰
```

### L3 - The Crystalï¼ˆç»“æ™¶å±‚ï¼‰

```mermaid
graph TB
subgraph "L3 PostgreSQL"
  FACTS[crystal_facts<br/>æ•´åˆäº‹å®]
  LINKS[crystal_links<br/>æŒä¹…åŒ–é“¾æ¥]
end
CLUSTER[é«˜é¢‘è®¿é—®é›†ç¾¤] -->|æ•´åˆ| FACTS
GRAPH[å›¾é“¾æ¥] -->|æŒä¹…åŒ–| LINKS
STARTUP[ç³»ç»Ÿå¯åŠ¨] -->|æ¢å¤| GRAPH
```

**èŒè´£**ï¼š
- æŒä¹…åŒ–å­˜å‚¨æ•´åˆåçš„äº‹å®ï¼ˆCrystalFactï¼‰
- æŒä¹…åŒ–å›¾é“¾æ¥ï¼Œæ”¯æŒé‡å¯æ¢å¤
- é•¿æœŸçŸ¥è¯†æ²‰æ·€

**æ•°æ®è¡¨ç»“æ„**ï¼š
```sql
CREATE TABLE crystal_facts (
  id UUID PRIMARY KEY,
  content TEXT NOT NULL,
  source_node_ids TEXT[],
  confidence FLOAT DEFAULT 1.0,
  created_at TIMESTAMP,
  updated_at TIMESTAMP,
  metadata JSONB
);
CREATE TABLE crystal_links (
  id SERIAL PRIMARY KEY,
  source_id VARCHAR(64),
  target_id VARCHAR(64),
  link_type VARCHAR(16),
  weight FLOAT DEFAULT 1.0,
  created_at TIMESTAMP,
  UNIQUE(source_id, target_id, link_type)
);
```

---

## æ ¸å¿ƒæ•°æ®ç»“æ„

### MemoryNodeï¼ˆè®°å¿†èŠ‚ç‚¹ï¼‰

```mermaid
classDiagram
class MemoryNode {
  +id: str
  +content: str
  +vector: list~float~
  +metadata: MemoryMetadata
  +energy: float
  +initial_energy: float
  +last_accessed: float
  +created_at: float
  +tier: str
  +links: list~Link~
  +touch()
  +add_link(link)
  +summarize()
}
class MemoryMetadata {
  +timestamp: float
  +location: str
  +entities: list~str~
  +sentiment: float
  +source: str
  +tags: list~str~
}
class Link {
  +source_id: str
  +target_id: str
  +link_type: LinkType
  +weight: float
  +created_at: float
}
MemoryNode --> MemoryMetadata
MemoryNode --> Link
```

### èƒ½é‡å…¬å¼

è®°å¿†èƒ½é‡éšæ—¶é—´æŒ‡æ•°è¡°å‡ï¼š

$$E(t) = E_0 \cdot e^{-\lambda \Delta t}$$

å…¶ä¸­ï¼š
- $E_0$ = åˆå§‹èƒ½é‡
- $\lambda$ = è¡°å‡ç³»æ•°ï¼ˆé»˜è®¤ 0.1ï¼‰
- $\Delta t$ = è‡ªä¸Šæ¬¡è®¿é—®çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰

---

## è¿è¡Œæ—¶ I/O äº¤äº’

### å†™å…¥æµç¨‹ï¼ˆIngestï¼‰

```mermaid
sequenceDiagram
  participant User as ç”¨æˆ·æ¶ˆæ¯
  participant Plugin as BIEMContextPlugin
  participant MM as MemoryManager
  participant Enc as Encoder
  participant Energy as EnergyController
  participant Tier as TierManager
  participant L1 as L1 Working
  participant L2V as L2 Vector
  participant L2G as L2 Graph
  participant L3 as L3 Crystal
  User->>Plugin: record_user_message(content)
  Plugin->>MM: ingest(content, source="user")
  Note over MM,Enc: 1. ç¼–ç é˜¶æ®µ
  MM->>Enc: encode(content)
  Enc->>Enc: extract_entities()
  Enc->>Enc: analyze_sentiment()
  Enc->>Enc: generate_embedding()
  Enc-->>MM: MemoryNode
  Note over MM,Energy: 2. èƒ½é‡è¯„ä¼°
  MM->>Energy: estimate_initial_energy(content)
  Energy-->>MM: energy = 0.7
  Note over MM,L2V: 3. å†²çªæ£€æµ‹
  MM->>L2V: search_by_vector(top_k=10)
  L2V-->>MM: similar_nodes
  MM->>MM: check_conflicts()
  Note over MM,L3: 4. å­˜å‚¨é˜¶æ®µ
  MM->>Tier: store(node)
  alt energy >= 0.5
    Tier->>L1: put(node)
    Note right of L1: tier = "L1"
  end
  Tier->>L2V: put(node)
  Note right of L2V: å§‹ç»ˆå†™å…¥å‘é‡åº“
  Tier->>L2G: add_node(node_id)
  Note over MM,L3: 5. å»ºç«‹é“¾æ¥
  MM->>L2G: route_new_node()
  L2G->>L2G: create temporal links
  L2G->>L2G: create semantic links
  L2G->>L3: store_link() [æŒä¹…åŒ–]
```

### è§¦å‘æ¡ä»¶æ€»ç»“

| æ“ä½œ | è§¦å‘æ¡ä»¶ | ç›®æ ‡å­˜å‚¨ |
|------|----------|----------|
| å†™å…¥ L1 | `energy >= 0.5` | Python Dict |
| å†™å…¥ L2 Vector | **å§‹ç»ˆ** | Milvus |
| æ·»åŠ å›¾èŠ‚ç‚¹ | **å§‹ç»ˆ** | NetworkX |
| å»ºç«‹ Temporal Link | ä¸æœ€è¿‘ 5 ä¸ªèŠ‚ç‚¹æ—¶é—´å·® < 5åˆ†é’Ÿ | NetworkX â†’ PostgreSQL |
| å»ºç«‹ Semantic Link | å‘é‡ç›¸ä¼¼åº¦ > 0.7 | NetworkX â†’ PostgreSQL |
| å†™å…¥ L3 Fact | é›†ç¾¤æ•´åˆï¼ˆâ‰¥5 èŠ‚ç‚¹ï¼‰ | PostgreSQL |

### è¯»å–æµç¨‹ï¼ˆRecallï¼‰

```mermaid
sequenceDiagram
  participant Query as æŸ¥è¯¢
  participant MM as MemoryManager
  participant Enc as Encoder
  participant L2V as L2 Vector
  participant L2G as L2 Graph
  participant Tier as TierManager
  Query->>MM: recall(query, top_k=5)
  Note over MM,Enc: 1. ç¼–ç æŸ¥è¯¢
  MM->>Enc: generate_embedding(query)
  Enc-->>MM: query_vector
  Note over MM,L2V: 2. å‘é‡æ£€ç´¢ï¼ˆStage 1ï¼‰
  MM->>L2V: search_by_vector(query_vector, top_k=10)
  L2V-->>MM: [(node, score), ...]
  Note over MM,L2G: 3. ä¼ æ’­æ¿€æ´»ï¼ˆStage 2ï¼‰
  MM->>L2G: spread_activation(seed_ids, hops=2)
  L2G->>L2G: BFS with decay
  L2G-->>MM: {node_id: activation_score}
  Note over MM,Tier: 4. èåˆæ’åº
  MM->>MM: combined = 0.7*vec_score + 0.3*activation
  MM->>Tier: get(node_id) for top results
  Note over Tier,Tier: 5. èƒ½é‡æå‡
  Tier->>Tier: boost_energy(node)
  MM-->>Query: [MemoryNode, ...]
```

### å±‚çº§æµåŠ¨

```mermaid
graph LR
subgraph "Promotionï¼ˆå‡çº§ï¼‰"
  L2_P[L2 èŠ‚ç‚¹] -->|energy >= 0.7<br/>è¢«é¢‘ç¹è®¿é—®| L1_P[L1]
end
subgraph "Demotionï¼ˆé™çº§ï¼‰"
  L1_D[L1 èŠ‚ç‚¹] -->|energy < 0.3<br/>é•¿æ—¶é—´æœªè®¿é—®| L2_D[L2]
  L2_D -->|æ•´åˆæ¡ä»¶æ»¡è¶³| L3_D[L3 Crystal]
end
style L1_P fill:#ff6b6b
style L2_P fill:#4ecdc4
style L1_D fill:#ff6b6b
style L2_D fill:#4ecdc4
style L3_D fill:#96ceb4
```

---

## ä¸ Agent Context çš„é›†æˆ

### è®¾è®¡åŸåˆ™

è®°å¿†ç³»ç»Ÿé‡‡ç”¨**åŠ¨æ€æ³¨å…¥**çš„æ–¹å¼ä¸ Agent é›†æˆï¼Œè€Œéé™æ€æ¨¡æ¿å ä½ç¬¦ï¼š

1. **è§£è€¦è®¾è®¡**ï¼šè®°å¿†ç³»ç»Ÿä½œä¸ºå¯é€‰æ’ä»¶ï¼Œä¸ä¿®æ”¹æ ¸å¿ƒ prompt æ¨¡æ¿
2. **ä½ç½®å›ºå®š**ï¼šé€šè¿‡ `ContextManager.build_messages()` ä¿è¯ sections é¡ºåºä¸€è‡´
3. **æŒ‰éœ€æ³¨å…¥**ï¼šåªæœ‰å¬å›åˆ°ç›¸å…³è®°å¿†æ—¶æ‰æ³¨å…¥ï¼Œé¿å…ç©ºç™½å ä½

### é›†æˆæ•°æ®æµ

```mermaid
graph TB
subgraph "Agent Loop"
  INPUT[ç”¨æˆ·è¾“å…¥] --> PREPARE
  subgraph "Memory Integration"
    PREPARE[prepare_context] --> RECALL
    RECALL[recall memories] --> FORMAT
    FORMAT[æ ¼å¼åŒ–è®°å¿†] --> INJECT
  end
  INJECT --> SYSTEM[System Prompt]
  SYSTEM --> LLM_CALL[LLM è°ƒç”¨]
  LLM_CALL --> RESPONSE[å“åº”ç”Ÿæˆ]
  RESPONSE --> RECORD_U[è®°å½•ç”¨æˆ·æ¶ˆæ¯]
  RECORD_U --> RECORD_A[è®°å½•åŠ©æ‰‹æ¶ˆæ¯]
end
subgraph "Context Window"
  SYSTEM
  USER_MSG[User Message]
  HISTORY[å¯¹è¯å†å²]
end
```

### é›†æˆä»£ç æµç¨‹

```python
# main.py ä¸­çš„é›†æˆé€»è¾‘
async def run_interactive(agent, loop, memory, knowledge):
  while True:
    user_input = get_user_input()
    context_parts = []
    # 1. å¬å›ç›¸å…³è®°å¿†
    if memory:
      memory_context = await memory.prepare_context(user_input)
      if memory_context:
        context_parts.append(memory_context)
    # 2. å¬å›ç›¸å…³çŸ¥è¯†
    if knowledge and knowledge.is_available():
      knowledge_context = await knowledge.get_context_for_query(user_input)
      if knowledge_context:
        context_parts.append(knowledge_context)
    # 3. æ³¨å…¥åˆ° Context
    if context_parts:
      agent.context.set_memory_context("\n\n".join(context_parts))
    # 4. LLM è°ƒç”¨
    response = await loop.run_stream(user_input)
    # 5. æ¸…é™¤è®°å¿†ä¸Šä¸‹æ–‡
    agent.context.clear_memory_context()
    # 6. è®°å½•æœ¬è½®å¯¹è¯
    if memory:
      await memory.record_user_message(user_input)
      await memory.record_assistant_message(response)
    # 7. çŸ¥è¯†æŠ½å–
    if knowledge:
      result = await knowledge.process_message(user_input)
      if result.has_pending_confirmation():
        # æ˜¾ç¤ºç¡®è®¤æç¤º
        for prompt in result.confirmation_prompts:
          print(prompt)
```

### Context æ„å»ºè¿‡ç¨‹

Agent çš„ context é€šè¿‡ `ContextManager.build_messages()` æ–¹æ³•é€æ­¥æ„å»ºï¼š

```mermaid
sequenceDiagram
  participant Agent as Agent
  participant CM as ContextManager
  participant LLM as LLM API
  Note over Agent,CM: 1. åˆå§‹åŒ–é˜¶æ®µ
  Agent->>CM: set_system_prompt(template)
  Note right of CM: æ¸²æŸ“æ¨¡æ¿:<br/>workspace, tools
  Note over Agent,CM: 2. ç”¨æˆ·è¾“å…¥é˜¶æ®µ
  Agent->>CM: set_memory_context(memories + knowledge)
  Note right of CM: æ³¨å…¥å¬å›çš„è®°å¿†å’ŒçŸ¥è¯†
  Note over Agent,CM: 3. æ„å»ºæ¶ˆæ¯é˜¶æ®µ
  Agent->>CM: build_messages()
  CM->>CM: 1. æ·»åŠ  system_prompt
  CM->>CM: 2. æ·»åŠ  memory_context
  CM->>CM: 3. æ·»åŠ  skills_summary
  CM->>CM: 4. æ·»åŠ  loaded_instructions
  CM->>CM: 5. æ·»åŠ  conversation history
  CM-->>Agent: messages[]
  Agent->>LLM: chat(messages)
  Note over Agent,CM: 4. æ¸…ç†é˜¶æ®µ
  Agent->>CM: clear_memory_context()
```

### build_messages() å®ç°é€»è¾‘

```python
def build_messages(self) -> list[dict]:
  """Section order (fixed for agent stability):
  1. System prompt (core instructions, workspace, tools)
  2. Memory context (relevant memories + knowledge)
  3. Skills summary (available skills list)
  4. Loaded skill instructions
  """
  system_content = self._system_prompt
  if self._memory_context:
    system_content += f"\n\n{self._memory_context}"
  skill_summary = self.get_skill_summary()
  if skill_summary:
    system_content += f"\n\n{skill_summary}"
  skill_instructions = self.get_loaded_skill_instructions()
  if skill_instructions:
    system_content += f"\n\n{skill_instructions}"
  messages = [{"role": "system", "content": system_content}]
  for msg in self._messages:
    messages.append(msg.to_openai_format())
  return messages
```

### æœ€ç»ˆ Context ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. System Prompt (é™æ€)               â”‚
â”‚ - Core Behavior Loop                   â”‚
â”‚ - Skill Loading Protocol               â”‚
â”‚ - Guidelines                           â”‚
â”‚ - Workspace & Tools                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Memory Context (åŠ¨æ€æ³¨å…¥)           â”‚
â”‚ ## Relevant Memories                   â”‚
â”‚ 1. [â— E=0.85] ...                      â”‚
â”‚ ## Learned Knowledge                   â”‚
â”‚ - (GPT-4, context_window, 128k)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Skills Summary (åŠ¨æ€)              â”‚
â”‚ - [â—‹] book-flight                     â”‚
â”‚ - [âœ“] codebase-tools                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Loaded Skill Instructions (åŠ¨æ€)   â”‚
â”‚ ### Skill: codebase-tools              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†‘ System Message ç»“æŸ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“ Conversation Messages å¼€å§‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Conversation History                â”‚
â”‚ [User]: ä¹‹å‰æˆ‘ä»¬èŠäº†ä»€ä¹ˆï¼Ÿ              â”‚
â”‚ [Assistant]: ...                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Current User Message                â”‚
â”‚ [User]: ç»™æˆ‘è®²è®² PyTorch çš„åŸºç¡€çŸ¥è¯†     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¬å›ç­–ç•¥

### ä¸¤é˜¶æ®µå¬å›ç®—æ³•

```mermaid
graph TB
subgraph "Stage 1: Vector Search"
  Q[æŸ¥è¯¢] --> QV[æŸ¥è¯¢å‘é‡]
  QV --> VS[Milvus ç›¸ä¼¼åº¦æ£€ç´¢]
  VS --> TOP10[Top 10 å€™é€‰]
end
subgraph "Stage 2: Spreading Activation"
  TOP10 --> SEEDS[ç§å­èŠ‚ç‚¹ Top 5]
  SEEDS --> HOP1[Hop 1<br/>decay=0.5]
  HOP1 --> HOP2[Hop 2<br/>decay=0.25]
  HOP2 --> ACTIVATED[æ¿€æ´»èŠ‚ç‚¹é›†åˆ]
end
subgraph "Score Fusion"
  TOP10 --> MERGE
  ACTIVATED --> MERGE[èåˆæ’åº]
  MERGE --> FORMULA["score = 0.7Ã—vec + 0.3Ã—activation"]
  FORMULA --> FINAL[æœ€ç»ˆ Top K]
end
```

### å¬å›é…ç½®å‚æ•°

```python
@dataclass
class MemoryConfig:
  default_recall_limit: int = 10          # é»˜è®¤è¿”å›æ•°é‡
  spreading_activation_hops: int = 2       # ä¼ æ’­è·³æ•°
  spreading_decay_factor: float = 0.5     # æ¯è·³è¡°å‡ç³»æ•°
```

### å¬å›å†…å®¹æ ¼å¼

```markdown
## Relevant Memories
1. [â— E=0.85] ç”¨æˆ·ä¹‹å‰æåˆ°æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œç‰¹åˆ«å¯¹æ·±åº¦å­¦ä¹ æ„Ÿå…´è¶£...
Entities: æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , PyTorch
2. [â—‹ E=0.62] æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ...
Entities: æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, åå‘ä¼ æ’­
3. [â—Œ E=0.41] PyTorch æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶...
Entities: PyTorch, TensorFlow, æ¡†æ¶
```

**èƒ½é‡æŒ‡ç¤ºå™¨**ï¼š
- `â—` = é«˜èƒ½é‡ (energy > 0.7)
- `â—‹` = ä¸­èƒ½é‡ (0.3 < energy â‰¤ 0.7)
- `â—Œ` = ä½èƒ½é‡ (energy â‰¤ 0.3)

---

## èƒ½é‡è¡°å‡æœºåˆ¶

### è¡°å‡ä¸å¢å¼º

```mermaid
graph LR
subgraph "Energy Dynamics"
  DECAY[æ—¶é—´è¡°å‡<br/>E = Eâ‚€ Ã— e^(-Î»Î”t)]
  BOOST[è®¿é—®å¢å¼º<br/>E += 0.1]
  FEEDBACK[åé¦ˆè°ƒèŠ‚<br/>E += feedback Ã— 0.1]
end
TIME[æ—¶é—´æµé€] --> DECAY
ACCESS[è¢«å¬å›/è®¿é—®] --> BOOST
USER[ç”¨æˆ·åé¦ˆ] --> FEEDBACK
```

### èƒ½é‡é˜ˆå€¼ä¸è¡Œä¸º

| èƒ½é‡èŒƒå›´ | çŠ¶æ€ | ç³»ç»Ÿè¡Œä¸º |
|----------|------|----------|
| `â‰¥ 0.7` | çƒ­è®°å¿† | å¯å‡çº§åˆ° L1 |
| `0.5 ~ 0.7` | æ¸©è®°å¿† | ä¿æŒåœ¨ L1 æˆ– L2 |
| `0.3 ~ 0.5` | å†·è®°å¿† | å¯èƒ½ä» L1 é™çº§ |
| `< 0.3` | é—å¿˜è¾¹ç¼˜ | ä» L1 é©±é€åˆ° L2 |
| `< 0.1` | æ¿’ä¸´é—å¿˜ | å¯èƒ½è¢«æ¸…ç† |

---

## çŸ¥è¯†å­¦ä¹ ç³»ç»Ÿ (Knowledge Learning)

BIEM è®°å¿†ç³»ç»Ÿçš„æ‰©å±•æ¨¡å—ï¼Œä»å¯¹è¯ä¸­æŠ½å–ç»“æ„åŒ–çŸ¥è¯†ä¸‰å…ƒç»„ï¼Œæ”¯æŒçŸ¥è¯†æ›´æ–°å’Œå†²çªæ£€æµ‹ã€‚

### ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
subgraph "å¯¹è¯è¾“å…¥"
  USER[ç”¨æˆ·æ¶ˆæ¯] --> PLUGIN[KnowledgeLearningPlugin]
end
subgraph "çŸ¥è¯†æŠ½å–"
  PLUGIN --> EXTRACT[KnowledgeExtractor<br/>LLM é©±åŠ¨]
  EXTRACT -->|JSON| TRIPLES[ä¸‰å…ƒç»„åˆ—è¡¨]
end
subgraph "å†²çªæ£€æµ‹"
  TRIPLES --> CONFLICT[ConflictDetector]
  CONFLICT -->|æ— å†²çª| STORE[ç›´æ¥å­˜å‚¨]
  CONFLICT -->|æœ‰å†²çª| CONFIRM[ConfirmationManager]
  CONFIRM -->|ç”¨æˆ·ç¡®è®¤| UPDATE[æ›´æ–°çŸ¥è¯†]
  CONFIRM -->|ç”¨æˆ·æ‹’ç»| KEEP[ä¿ç•™åŸçŸ¥è¯†]
end
subgraph "å­˜å‚¨å±‚"
  STORE --> PG[(PostgreSQL<br/>knowledge_triples)]
  UPDATE --> PG
  STORE --> MV[(Milvus<br/>å‘é‡ç´¢å¼•)]
  PG --> HISTORY[(knowledge_history<br/>ç‰ˆæœ¬å†å²)]
end
style EXTRACT fill:#ff6188,color:#fff
style PG fill:#96ceb4,color:#fff
style MV fill:#4ecdc4,color:#fff
```

### çŸ¥è¯†ä¸‰å…ƒç»„ (KnowledgeTriple)

çŸ¥è¯†ä»¥ `(Subject, Predicate, Object)` ä¸‰å…ƒç»„å½¢å¼å­˜å‚¨ï¼š

```python
@dataclass
class KnowledgeTriple:
  id: str                     # UUID
  subject: str                # ä¸»ä½“: "GPT-4", "Python"
  predicate: str              # å…³ç³»: "context_window", "created_by"
  object: str                 # å®¢ä½“: "128k tokens", "Guido"
  confidence: float = 0.8     # ç½®ä¿¡åº¦ 0.0~1.0
  source: KnowledgeSource     # æ¥æºç±»å‹
  version: int = 1            # ç‰ˆæœ¬å· (æ›´æ–°æ—¶é€’å¢)
  previous_values: list[str]  # å†å²å€¼
  session_id: str             # åˆ›å»º Session
  user_id: str                # æ‰€å±ç”¨æˆ· (å¤šç”¨æˆ·éš”ç¦»)
  created_at: float           # åˆ›å»ºæ—¶é—´æˆ³
  updated_at: float           # æ›´æ–°æ—¶é—´æˆ³
  vector: list[float]         # å‘é‡åµŒå…¥ (è¯­ä¹‰æ£€ç´¢)
```

| Subject | Predicate | Object |
|---------|-----------|--------|
| GPT-4 | context_window | 128k tokens |
| Python | created_by | Guido van Rossum |
| Claude 3.5 | max_output | 8k tokens |

### çŸ¥è¯†æ„å›¾ (KnowledgeIntent)

```python
class KnowledgeIntent(str, Enum):
  STATEMENT = "statement"     # æ­£å¸¸äº‹å®é™ˆè¿°
  CORRECTION = "correction"   # çº æ­£ä¹‹å‰çš„ä¿¡æ¯
  QUESTION = "question"       # è¯¢é—®æŸçŸ¥è¯†
  OPINION = "opinion"         # ä¸»è§‚è§‚ç‚¹ (ä¸å­˜å‚¨)
```

### çŸ¥è¯†æ¥æº (KnowledgeSource)

```python
class KnowledgeSource(str, Enum):
  CONVERSATION = "conversation"       # å¯¹è¯ä¸­æå–
  USER_STATED = "user_stated"         # ç”¨æˆ·æ˜ç¡®é™ˆè¿°
  USER_CORRECTION = "user_correction" # ç”¨æˆ·çº æ­£
  USER_VERIFIED = "user_verified"     # ç”¨æˆ·ç¡®è®¤æ›´æ–°
  AGENT_INFERRED = "agent_inferred"   # Agent æ¨æ–­
```

### æŠ½å–ç»“æœ (ExtractionResult)

```python
@dataclass
class ExtractionResult:
  is_factual: bool = False        # æ˜¯å¦åŒ…å«äº‹å®å†…å®¹
  intent: KnowledgeIntent         # ç”¨æˆ·æ„å›¾
  triples: list[KnowledgeTriple]  # æŠ½å–çš„ä¸‰å…ƒç»„
  confidence: float = 0.0         # æŠ½å–ç½®ä¿¡åº¦
  raw_message: str = ""           # åŸå§‹æ¶ˆæ¯
```

### å†²çªç»“æœ (ConflictResult)

```python
@dataclass
class ConflictResult:
  has_conflict: bool = False
  existing_triple: KnowledgeTriple | None = None
  new_triple: KnowledgeTriple | None = None
  conflict_type: str = ""         # "value_change", "contradiction"
  suggestion: str = ""            # äººç±»å¯è¯»å»ºè®®
```

### å¾…ç¡®è®¤æ›´æ–° (PendingUpdate)

```python
@dataclass
class PendingUpdate:
  id: str
  new_triple: KnowledgeTriple
  existing_triple: KnowledgeTriple | None
  confirmation_message: str
  expires_at: float  # 5åˆ†é’Ÿè¶…æ—¶
```

### çŸ¥è¯†æŠ½å–æµç¨‹

```mermaid
sequenceDiagram
  participant User as ç”¨æˆ·
  participant Plugin as KnowledgeLearningPlugin
  participant Extractor as KnowledgeExtractor
  participant LLM as LLM
  participant Detector as ConflictDetector
  participant Store as KnowledgeStore
  User->>Plugin: "Claude 3.5 Sonnet çš„ä¸Šä¸‹æ–‡æ˜¯ 200k"
  Plugin->>Extractor: extract(message)
  Extractor->>LLM: åˆ†ææ¶ˆæ¯ï¼ŒæŠ½å–ä¸‰å…ƒç»„
  LLM-->>Extractor: {is_factual: true, triples: [...]}
  Extractor-->>Plugin: ExtractionResult
  Plugin->>Detector: check(triple)
  Detector->>Store: find_potential_conflicts()
  alt æ— å†²çª
    Store-->>Detector: []
    Detector-->>Plugin: ConflictResult(has_conflict=false)
    Plugin->>Store: store(triple)
    Plugin-->>User: ğŸ“š Learned 1 new fact(s)
  else æœ‰å†²çª
    Store-->>Detector: [existing_triple]
    Detector-->>Plugin: ConflictResult(has_conflict=true)
    Plugin-->>User: â“ æˆ‘è®°å¾—æ˜¯ Xï¼Œç¡®è®¤æ›´æ–°ä¸º Y å—ï¼Ÿ
  end
```

### å†²çªç¡®è®¤æµç¨‹

å½“æ£€æµ‹åˆ°æ–°çŸ¥è¯†ä¸å·²æœ‰çŸ¥è¯†å†²çªæ—¶ï¼š

```
Session 1:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç”¨æˆ·: GPT-4 çš„ä¸Šä¸‹æ–‡çª—å£æ˜¯ 32k
Agent: ğŸ“š Learned 1 new fact(s)
[å­˜å‚¨: (GPT-4, context_window, 32k)]

Session 2:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç”¨æˆ·: å…¶å® GPT-4 ç°åœ¨æ”¯æŒ 128k äº†
Agent: â“ æˆ‘è®°å¾— GPT-4 çš„ context window æ˜¯ 32k tokensï¼Œ
      æ‚¨ç¡®è®¤æ›´æ–°ä¸º 128k äº†å—ï¼Ÿ
ç”¨æˆ·: æ˜¯çš„
Agent: å¥½çš„ï¼ŒçŸ¥è¯†å·²æ›´æ–°ï¼
[æ›´æ–°: (GPT-4, context_window, 128k), version=2]
```

### è·¨ Session çŸ¥è¯†å¬å›

çŸ¥è¯†åœ¨æ–° Session ä¸­è‡ªåŠ¨æ³¨å…¥ç›¸å…³ä¸Šä¸‹æ–‡ï¼š

```mermaid
graph LR
subgraph "æ–° Session"
  Q[ç”¨æˆ·: ç¥ç»ç½‘ç»œæ€ä¹ˆè®­ç»ƒ?] --> SEARCH
end
subgraph "çŸ¥è¯†æ£€ç´¢"
  SEARCH[è¯­ä¹‰æœç´¢] --> PG[(PostgreSQL)]
  SEARCH --> MV[(Milvus)]
  PG --> RESULTS[ç›¸å…³ä¸‰å…ƒç»„]
  MV --> RESULTS
end
subgraph "Context æ³¨å…¥"
  RESULTS --> FORMAT[æ ¼å¼åŒ–]
  FORMAT --> INJECT["## Learned Knowledge<br/>- (GPT-4, context_window, 128k)"]
end
```

### æ•°æ®åº“ Schema

```sql
-- çŸ¥è¯†ä¸‰å…ƒç»„è¡¨
CREATE TABLE knowledge_triples (
  id UUID PRIMARY KEY,
  subject VARCHAR(255) NOT NULL,
  predicate VARCHAR(255) NOT NULL,
  object TEXT NOT NULL,
  confidence FLOAT DEFAULT 0.8,
  source VARCHAR(32),
  version INT DEFAULT 1,
  previous_values JSONB DEFAULT '[]',
  user_id VARCHAR(64),
  session_id VARCHAR(64),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, subject, predicate)
);
-- çŸ¥è¯†æ›´æ–°å†å²è¡¨
CREATE TABLE knowledge_history (
  id UUID PRIMARY KEY,
  triple_id UUID REFERENCES knowledge_triples(id),
  old_value TEXT,
  new_value TEXT,
  reason VARCHAR(64),
  confirmed BOOLEAN DEFAULT false,
  session_id VARCHAR(64),
  timestamp TIMESTAMPTZ DEFAULT NOW()
);
```

### ä¸ Memory Context çš„èåˆ

çŸ¥è¯†ä¸Šä¸‹æ–‡ä¸è®°å¿†ä¸Šä¸‹æ–‡åˆå¹¶æ³¨å…¥ï¼š

```python
# main.py é›†æˆé€»è¾‘
context_parts = []
if memory:
  memory_context = await memory.prepare_context(user_input)
  if memory_context:
    context_parts.append(memory_context)
if knowledge and knowledge.is_available():
  knowledge_context = await knowledge.get_context_for_query(user_input)
  if knowledge_context:
    context_parts.append(knowledge_context)
agent.context.set_memory_context("\n\n".join(context_parts))
```

**æœ€ç»ˆæ³¨å…¥æ ¼å¼**ï¼š

```markdown
## Relevant Memories
1. [â— E=0.85] ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ...
Entities: æœºå™¨å­¦ä¹ , PyTorch

## Learned Knowledge
- (GPT-4, context_window, 128k tokens) [user_verified]
- (Claude 3.5, max_output, 8k tokens) [user_stated]
```

### é…ç½®å‚æ•°

```python
@dataclass
class KnowledgePluginConfig:
  store_config: KnowledgeStoreConfig    # PostgreSQL é…ç½®
  vector_config: KnowledgeVectorConfig  # Milvus é…ç½®
  extractor_config: ExtractorConfig     # LLM æŠ½å–é…ç½®
  conflict_config: ConflictConfig       # å†²çªæ£€æµ‹é…ç½®
  auto_store: bool = True               # è‡ªåŠ¨å­˜å‚¨æ— å†²çªçŸ¥è¯†
  extract_from_agent: bool = False      # æ˜¯å¦ä» Agent æ¶ˆæ¯æŠ½å–
  max_context_items: int = 10           # Context ä¸­æœ€å¤§çŸ¥è¯†æ¡æ•°
  enable_vector_search: bool = True     # å¯ç”¨å‘é‡è¯­ä¹‰æœç´¢
  user_id: str = ""                     # ç”¨æˆ· ID (å¤šç”¨æˆ·éš”ç¦»)
  session_id: str = ""                  # Session ID
```

---

## é™„å½•ï¼šé…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡

```bash
# Milvus é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=biem_memories
MILVUS_USE_LITE=false
# PostgreSQL é…ç½®
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=biem
POSTGRES_USER=your_user
POSTGRES_PASSWORD=
# è®°å¿†ç³»ç»Ÿå¼€å…³
DISABLE_MEMORY=false
# çŸ¥è¯†å­¦ä¹ å¼€å…³
DISABLE_KNOWLEDGE=false
KNOWLEDGE_VECTOR_SEARCH=true
USER_ID=default
```

### å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨ Milvus (Docker)
docker compose -f docker-compose.milvus.yml up -d
# å¯åŠ¨ PostgreSQL (å¦‚æœä½¿ç”¨æœ¬åœ°)
brew services start postgresql@18
# åˆ›å»ºæ•°æ®åº“
psql -U your_user -c "CREATE DATABASE biem;"
# è¿è¡Œ Agent
uv run python main.py
```

### å¯è§†åŒ–ç•Œé¢

```bash
# å¯åŠ¨ Web å¯è§†åŒ– (Monokai Pro ä¸»é¢˜)
uv run uvicorn src.omniemployee.web.app:app --port 8765
# è®¿é—® http://localhost:8765
```

åŠŸèƒ½åŒ…æ‹¬ï¼š
- **L1 Working Memory**: å½“å‰å·¥ä½œè®°å¿†èŠ‚ç‚¹åˆ—è¡¨
- **L2 Vector Storage**: å‘é‡å­˜å‚¨ç»Ÿè®¡å’ŒèŠ‚ç‚¹é¢„è§ˆ
- **L2 Graph**: D3.js åŠ›å¯¼å‘å›¾å¯è§†åŒ–èŠ‚ç‚¹å…³è”
- **L3 Facts/Links**: PostgreSQL æŒä¹…åŒ–æ•°æ®è¡¨æ ¼è§†å›¾
- **Knowledge**: å­¦ä¹ åˆ°çš„çŸ¥è¯†ä¸‰å…ƒç»„åˆ—è¡¨
