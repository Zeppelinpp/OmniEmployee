# BIEM è®°å¿†ç³»ç»ŸæŠ€æœ¯æ–‡æ¡£

> **Bio-Inspired Evolving Memory (BIEM)** â€” ä¸€ä¸ªä»¿ç”Ÿå­¦å¯å‘çš„å¤šå±‚çº§è®°å¿†ç³»ç»Ÿ

---

## ç³»ç»Ÿæ¦‚è¿°

BIEM æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿäººç±»è®°å¿†æœºåˆ¶çš„å¤šå±‚çº§è®°å¿†ç³»ç»Ÿï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š

- **èƒ½é‡è¡°å‡**ï¼šè®°å¿†éšæ—¶é—´è‡ªç„¶é—å¿˜ï¼Œé¢‘ç¹è®¿é—®çš„è®°å¿†ä¿æŒæ´»è·ƒ
- **å…³è”æ¿€æ´»**ï¼šé€šè¿‡å›¾ç»“æ„å®ç°è®°å¿†é—´çš„è”æƒ³ä¼ æ’­
- **å†²çªæ£€æµ‹**ï¼šè¯†åˆ«æ–°æ—§ä¿¡æ¯ä¹‹é—´çš„è®¤çŸ¥å¤±è°ƒ
- **å±‚çº§æµåŠ¨**ï¼šè®°å¿†åœ¨ä¸åŒå±‚çº§é—´æ ¹æ®"çƒ­åº¦"è‡ªåŠ¨å‡é™
- **çŸ¥è¯†å­¦ä¹ **ï¼šä»å¯¹è¯ä¸­æŠ½å–ç»“æ„åŒ–ä¸‰å…ƒç»„çŸ¥è¯†ï¼Œæ”¯æŒæ›´æ–°å’Œå†²çªæ£€æµ‹
- **ç”¨æˆ·éš”ç¦»**ï¼šè®°å¿†æŒ‰ç”¨æˆ·éš”ç¦»ï¼Œæ¯ä¸ªç”¨æˆ·æœ‰ç‹¬ç«‹çš„è®°å¿†ç©ºé—´
- **å…¨å±€çŸ¥è¯†**ï¼šçŸ¥è¯†åº“å…¨å±€å…±äº«ï¼Œæ‰€æœ‰ç”¨æˆ·è´¡çŒ®å’Œè®¿é—®åŒä¸€çŸ¥è¯†å›¾è°±

### æ•°æ®éš”ç¦»æ¨¡å‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BIEM æ•°æ®éš”ç¦»æ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   User A ğŸ‘¤     â”‚  â”‚   User B ğŸ‘¤     â”‚   Per-User        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   Memory          â”‚
â”‚  â”‚  â”‚ L1 Cache  â”‚  â”‚  â”‚  â”‚ L1 Cache  â”‚  â”‚   Isolation       â”‚
â”‚  â”‚  â”‚ L2 Vector â”‚  â”‚  â”‚  â”‚ L2 Vector â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚ L2 Graph  â”‚  â”‚  â”‚  â”‚ L2 Graph  â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚ L3 Crystalâ”‚  â”‚  â”‚  â”‚ L3 Crystalâ”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Knowledge Base ğŸŒ                       â”‚    â”‚
â”‚  â”‚         (Global, Shared Across All Users)           â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚   â”‚  (Python, created_by, Guido van Rossum)   â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  (GPT-4, context_window, 128k tokens)     â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  (Machine Learning, subset_of, AI)        â”‚    â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| æ•°æ®ç±»å‹ | éš”ç¦»æ¨¡å¼ | è¯´æ˜ |
|----------|----------|------|
| **è®°å¿† (Memory)** | ğŸ‘¤ Per-User | L1/L2/L3 å…¨éƒ¨æŒ‰ `user_id` éš”ç¦» |
| **çŸ¥è¯† (Knowledge)** | ğŸŒ Global | æ‰€æœ‰ç”¨æˆ·å…±äº«åŒä¸€çŸ¥è¯†åº“ |

### ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```mermaid
graph TB
subgraph "Agent Runtime"
  USER[ç”¨æˆ·è¾“å…¥] --> PLUGIN[BIEMContextPlugin]
  PLUGIN --> MM[MemoryManager]
  USER --> KL[KnowledgeLearningPlugin]
  MM --> CONTEXT[Context æ³¨å…¥]
  KL --> CONTEXT
  CONTEXT --> LLM[LLM è°ƒç”¨]
  LLM --> RESPONSE[å“åº”è¾“å‡º]
  RESPONSE --> RECORD[è®°å½•åˆ°è®°å¿†]
  RESPONSE --> KLEARN[çŸ¥è¯†æŠ½å–]
end
subgraph "Memory Tiers (Per-User ğŸ‘¤)"
  MM --> L1[L1 Working Canvas<br/>Python Dict]
  MM --> L2V[L2 Vector Storage<br/>Milvus + user_id]
  MM --> L2G[L2 Graph Storage<br/>NetworkX per user]
  MM --> L3[L3 Crystal<br/>PostgreSQL + user_id]
end
subgraph "Knowledge Storage (Global ğŸŒ)"
  KL --> KPG[(PostgreSQL<br/>knowledge_triples)]
  KL --> KMV[(Milvus<br/>biem_knowledge)]
  KLEARN --> KL
end
subgraph "Operators"
  MM --> ENC[Encoder<br/>Ollama BGE-M3]
  MM --> ENERGY[EnergyController]
  MM --> ROUTER[AssociationRouter]
  MM --> CONFLICT[ConflictChecker]
end
style L1 fill:#ff6b6b,color:#fff
style L2V fill:#4ecdc4,color:#fff
style L2G fill:#45b7d1,color:#fff
style L3 fill:#96ceb4,color:#fff
style KPG fill:#a8e6cf,color:#333
style KMV fill:#a8e6cf,color:#333
```

---

## ä¸‰å±‚è®°å¿†æ¶æ„

### å±‚çº§æ¦‚å¿µå¯¹æ¯”

| å±‚çº§ | åç§° | ç±»æ¯” | å­˜å‚¨ä»‹è´¨ | ç‰¹ç‚¹ |
|------|------|------|----------|------|
| **L1** | Working Canvas | å·¥ä½œè®°å¿† | Python Dict | é«˜é€Ÿã€æ˜“å¤±ã€å®¹é‡å° |
| **L2** | Association Web | é•¿æœŸè®°å¿† | Milvus + NetworkX | å‘é‡æ£€ç´¢ + å›¾å…³è” |
| **L3** | The Crystal | ç»“æ™¶çŸ¥è¯† | PostgreSQL | æŒä¹…åŒ–äº‹å®ä¸é“¾æ¥ |

### L1 - Working Canvasï¼ˆå·¥ä½œç”»å¸ƒï¼‰

```mermaid
graph LR
subgraph "L1 Working Memory"
  direction TB
  N1[Node A<br/>E=0.95]
  N2[Node B<br/>E=0.82]
  N3[Node C<br/>E=0.71]
  N4[Node D<br/>E=0.58]
  EVICT[...ä½èƒ½é‡èŠ‚ç‚¹è¢«é©±é€]
end
NEW[æ–°é«˜èƒ½é‡èŠ‚ç‚¹] -->|èƒ½é‡ â‰¥ 0.5| N1
N4 -->|èƒ½é‡ < 0.3| DEMOTE[é™çº§åˆ° L2]
style N1 fill:#ff6b6b
style N2 fill:#ff8585
style N3 fill:#ffa0a0
style N4 fill:#ffbaba
```

**èŒè´£**ï¼š
- å­˜å‚¨å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„é«˜èƒ½é‡èŠ‚ç‚¹
- å®¹é‡é™åˆ¶ï¼ˆé»˜è®¤ 100 èŠ‚ç‚¹ï¼‰ï¼Œè¶…é™æ—¶é©±é€ä½èƒ½é‡èŠ‚ç‚¹
- æä¾›æœ€å¿«çš„è®¿é—®é€Ÿåº¦

**é…ç½®å‚æ•°**ï¼š
```python
@dataclass
class L1Config:
  max_nodes: int = 100       # æœ€å¤§å®¹é‡
  ttl_seconds: float = 3600  # éæ´»è·ƒè¶…æ—¶ (1å°æ—¶)
  min_energy: float = 0.1    # æœ€ä½èƒ½é‡é˜ˆå€¼
```

### L2 - Association Webï¼ˆå…³è”ç½‘ç»œï¼‰

L2 ç”±ä¸¤ä¸ªå­ç³»ç»Ÿç»„æˆï¼š

```mermaid
graph TB
subgraph "L2 Association Web"
  subgraph "Vector Storage (Milvus)"
    V1[èŠ‚ç‚¹å‘é‡<br/>1024ç»´]
    V2[å…ƒæ•°æ®ç´¢å¼•]
    V3[ç›¸ä¼¼åº¦æ£€ç´¢]
  end
  subgraph "Graph Storage (NetworkX)"
    G1((A)) -->|temporal| G2((B))
    G2 -->|semantic| G3((C))
    G1 -->|causal| G3
    G3 -->|temporal| G4((D))
  end
end
QUERY[æŸ¥è¯¢å‘é‡] --> V3
V3 --> SEEDS[ç§å­èŠ‚ç‚¹]
SEEDS --> G1
G1 -->|ä¼ æ’­æ¿€æ´»| EXPAND[æ‰©å±•å¬å›]
```

#### L2-Vector (Milvus)

**èŒè´£**ï¼š
- å­˜å‚¨æ‰€æœ‰è®°å¿†èŠ‚ç‚¹çš„å‘é‡åµŒå…¥
- æ”¯æŒé«˜æ•ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
- æ ‡é‡å­—æ®µè¿‡æ»¤ï¼ˆèƒ½é‡ã€æ—¶é—´æˆ³ã€æƒ…æ„Ÿç­‰ï¼‰

**æ•°æ®æ¨¡å¼**ï¼š
```sql
-- Milvus Collection Schema (biem_memories)
id VARCHAR(64) PRIMARY KEY        -- UUID
user_id VARCHAR(64)              -- ç”¨æˆ· ID (éš”ç¦»é”®)
content VARCHAR(65535)           -- åŸæ–‡å†…å®¹
vector FLOAT_VECTOR(1024)        -- BGE-M3 åµŒå…¥
energy FLOAT                     -- èƒ½é‡å€¼ [0,1]
timestamp INT64                  -- åˆ›å»ºæ—¶é—´æˆ³
last_accessed INT64              -- æœ€åè®¿é—®æ—¶é—´
tier VARCHAR(8)                  -- å½“å‰å±‚çº§
sentiment FLOAT                  -- æƒ…æ„Ÿææ€§ [-1,1]
```

**æŸ¥è¯¢è¿‡æ»¤**ï¼šæ‰€æœ‰å‘é‡æ£€ç´¢éƒ½åŒ…å« `user_id == "{current_user}"` è¿‡æ»¤æ¡ä»¶

#### L2-Graph (NetworkX)

**èŒè´£**ï¼š
- ç»´æŠ¤èŠ‚ç‚¹é—´çš„å…³è”å…³ç³»
- æ”¯æŒä¼ æ’­æ¿€æ´»ï¼ˆSpreading Activationï¼‰å¬å›
- ä¸‰ç§é“¾æ¥ç±»å‹ï¼štemporalã€semanticã€causal

**é“¾æ¥ç±»å‹**ï¼š
```python
class LinkType(Enum):
  TEMPORAL = "temporal"  # æ—¶åºå…³ç³»ï¼ˆåŒä¸€å¯¹è¯/æ—¶é—´çª—å£ï¼‰
  SEMANTIC = "semantic"  # è¯­ä¹‰ç›¸ä¼¼ï¼ˆå‘é‡ç›¸ä¼¼åº¦ > 0.7ï¼‰
  CAUSAL = "causal"      # å› æœå…³ç³»ï¼ˆåé¦ˆå­¦ä¹ å»ºç«‹ï¼‰
```

### L3 - The Crystalï¼ˆç»“æ™¶å±‚ï¼‰

```mermaid
graph TB
subgraph "L3 PostgreSQL"
  FACTS[crystal_facts<br/>æ•´åˆäº‹å®]
  LINKS[crystal_links<br/>æŒä¹…åŒ–é“¾æ¥]
end
CLUSTER[é«˜é¢‘è®¿é—®é›†ç¾¤] -->|æ•´åˆ| FACTS
GRAPH[å›¾é“¾æ¥] -->|æŒä¹…åŒ–| LINKS
STARTUP[ç³»ç»Ÿå¯åŠ¨] -->|æ¢å¤| GRAPH
```

**èŒè´£**ï¼š
- æŒä¹…åŒ–å­˜å‚¨æ•´åˆåçš„äº‹å®ï¼ˆCrystalFactï¼‰
- æŒä¹…åŒ–å›¾é“¾æ¥ï¼Œæ”¯æŒé‡å¯æ¢å¤
- é•¿æœŸçŸ¥è¯†æ²‰æ·€

**æ•°æ®è¡¨ç»“æ„**ï¼š
```sql
CREATE TABLE crystal_facts (
  id UUID PRIMARY KEY,
  user_id VARCHAR(64) DEFAULT '',   -- ç”¨æˆ·éš”ç¦»
  content TEXT NOT NULL,
  source_node_ids UUID[] DEFAULT '{}',
  confidence FLOAT DEFAULT 1.0,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  metadata JSONB DEFAULT '{}'
);

CREATE INDEX idx_facts_user ON crystal_facts(user_id);

CREATE TABLE crystal_links (
  id UUID PRIMARY KEY,
  user_id VARCHAR(64) DEFAULT '',   -- ç”¨æˆ·éš”ç¦»
  source_id UUID NOT NULL,
  target_id UUID NOT NULL,
  link_type VARCHAR(16) NOT NULL,
  weight FLOAT DEFAULT 1.0,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(source_id, target_id, link_type)
);

CREATE INDEX idx_links_user ON crystal_links(user_id);
```

---

## æ ¸å¿ƒæ•°æ®ç»“æ„

### MemoryNodeï¼ˆè®°å¿†èŠ‚ç‚¹ï¼‰

```mermaid
classDiagram
class MemoryNode {
  +id: str
  +user_id: str
  +content: str
  +vector: list~float~
  +metadata: MemoryMetadata
  +energy: float
  +initial_energy: float
  +last_accessed: float
  +created_at: float
  +tier: str
  +links: list~Link~
  +touch()
  +add_link(link)
  +summarize()
}
class MemoryMetadata {
  +timestamp: float
  +location: str
  +entities: list~str~
  +sentiment: float
  +source: str
  +tags: list~str~
}
class Link {
  +source_id: str
  +target_id: str
  +link_type: LinkType
  +weight: float
  +created_at: float
  +user_id: str
}
MemoryNode --> MemoryMetadata
MemoryNode --> Link
```

**ç”¨æˆ·éš”ç¦»**ï¼š
- `user_id` å­—æ®µç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„è®°å¿†
- æ‰€æœ‰å­˜å‚¨å±‚ï¼ˆL1/L2/L3ï¼‰éƒ½æŒ‰ `user_id` è¿‡æ»¤
- åˆ‡æ¢ç”¨æˆ·åï¼Œåªèƒ½è®¿é—®è¯¥ç”¨æˆ·çš„è®°å¿†æ•°æ®

### èƒ½é‡å…¬å¼

è®°å¿†èƒ½é‡éšæ—¶é—´æŒ‡æ•°è¡°å‡ï¼š

$$E(t) = E_0 \cdot e^{-\lambda \Delta t}$$

å…¶ä¸­ï¼š
- $E_0$ = åˆå§‹èƒ½é‡
- $\lambda$ = è¡°å‡ç³»æ•°ï¼ˆé»˜è®¤ 0.1ï¼‰
- $\Delta t$ = è‡ªä¸Šæ¬¡è®¿é—®çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰

---

## è¿è¡Œæ—¶ I/O äº¤äº’

### å†™å…¥æµç¨‹ï¼ˆIngestï¼‰

```mermaid
sequenceDiagram
  participant User as ç”¨æˆ·æ¶ˆæ¯
  participant Plugin as BIEMContextPlugin
  participant MM as MemoryManager
  participant Enc as Encoder
  participant Energy as EnergyController
  participant Tier as TierManager
  participant L1 as L1 Working
  participant L2V as L2 Vector
  participant L2G as L2 Graph
  participant L3 as L3 Crystal
  User->>Plugin: record_user_message(content)
  Plugin->>MM: ingest(content, source="user")
  Note over MM,Enc: 1. ç¼–ç é˜¶æ®µ
  MM->>Enc: encode(content)
  Enc->>Enc: extract_entities()
  Enc->>Enc: analyze_sentiment()
  Enc->>Enc: generate_embedding()
  Enc-->>MM: MemoryNode
  Note over MM,Energy: 2. èƒ½é‡è¯„ä¼°
  MM->>Energy: estimate_initial_energy(content)
  Energy-->>MM: energy = 0.7
  Note over MM,L2V: 3. å†²çªæ£€æµ‹
  MM->>L2V: search_by_vector(top_k=10)
  L2V-->>MM: similar_nodes
  MM->>MM: check_conflicts()
  Note over MM,L3: 4. å­˜å‚¨é˜¶æ®µ
  MM->>Tier: store(node)
  alt energy >= 0.5
    Tier->>L1: put(node)
    Note right of L1: tier = "L1"
  end
  Tier->>L2V: put(node)
  Note right of L2V: å§‹ç»ˆå†™å…¥å‘é‡åº“
  Tier->>L2G: add_node(node_id)
  Note over MM,L3: 5. å»ºç«‹é“¾æ¥
  MM->>L2G: route_new_node()
  L2G->>L2G: create temporal links
  L2G->>L2G: create semantic links
  L2G->>L3: store_link() [æŒä¹…åŒ–]
```

### è§¦å‘æ¡ä»¶æ€»ç»“

| æ“ä½œ | è§¦å‘æ¡ä»¶ | ç›®æ ‡å­˜å‚¨ |
|------|----------|----------|
| å†™å…¥ L1 | `energy >= 0.5` | Python Dict |
| å†™å…¥ L2 Vector | **å§‹ç»ˆ** | Milvus |
| æ·»åŠ å›¾èŠ‚ç‚¹ | **å§‹ç»ˆ** | NetworkX |
| å»ºç«‹ Temporal Link | ä¸æœ€è¿‘ 5 ä¸ªèŠ‚ç‚¹æ—¶é—´å·® < 5åˆ†é’Ÿ | NetworkX â†’ PostgreSQL |
| å»ºç«‹ Semantic Link | å‘é‡ç›¸ä¼¼åº¦ > 0.7 | NetworkX â†’ PostgreSQL |
| å†™å…¥ L3 Fact | é›†ç¾¤æ•´åˆï¼ˆâ‰¥5 èŠ‚ç‚¹ï¼‰ | PostgreSQL |

### è¯»å–æµç¨‹ï¼ˆRecallï¼‰

```mermaid
sequenceDiagram
  participant Query as æŸ¥è¯¢
  participant MM as MemoryManager
  participant Enc as Encoder
  participant L2V as L2 Vector
  participant L2G as L2 Graph
  participant Tier as TierManager
  Query->>MM: recall(query, top_k=5)
  Note over MM,Enc: 1. ç¼–ç æŸ¥è¯¢
  MM->>Enc: generate_embedding(query)
  Enc-->>MM: query_vector
  Note over MM,L2V: 2. å‘é‡æ£€ç´¢ï¼ˆStage 1ï¼‰
  MM->>L2V: search_by_vector(query_vector, top_k=10)
  L2V-->>MM: [(node, score), ...]
  Note over MM,L2G: 3. ä¼ æ’­æ¿€æ´»ï¼ˆStage 2ï¼‰
  MM->>L2G: spread_activation(seed_ids, hops=2)
  L2G->>L2G: BFS with decay
  L2G-->>MM: {node_id: activation_score}
  Note over MM,Tier: 4. èåˆæ’åº
  MM->>MM: combined = 0.7*vec_score + 0.3*activation
  MM->>Tier: get(node_id) for top results
  Note over Tier,Tier: 5. èƒ½é‡æå‡
  Tier->>Tier: boost_energy(node)
  MM-->>Query: [MemoryNode, ...]
```

### å±‚çº§æµåŠ¨

```mermaid
graph LR
subgraph "Promotionï¼ˆå‡çº§ï¼‰"
  L2_P[L2 èŠ‚ç‚¹] -->|energy >= 0.7<br/>è¢«é¢‘ç¹è®¿é—®| L1_P[L1]
end
subgraph "Demotionï¼ˆé™çº§ï¼‰"
  L1_D[L1 èŠ‚ç‚¹] -->|energy < 0.3<br/>é•¿æ—¶é—´æœªè®¿é—®| L2_D[L2]
  L2_D -->|æ•´åˆæ¡ä»¶æ»¡è¶³| L3_D[L3 Crystal]
end
style L1_P fill:#ff6b6b
style L2_P fill:#4ecdc4
style L1_D fill:#ff6b6b
style L2_D fill:#4ecdc4
style L3_D fill:#96ceb4
```

---

## ä¸ Agent Context çš„é›†æˆ

### è®¾è®¡åŸåˆ™

è®°å¿†ç³»ç»Ÿé‡‡ç”¨**åŠ¨æ€æ³¨å…¥**çš„æ–¹å¼ä¸ Agent é›†æˆï¼Œè€Œéé™æ€æ¨¡æ¿å ä½ç¬¦ï¼š

1. **è§£è€¦è®¾è®¡**ï¼šè®°å¿†ç³»ç»Ÿä½œä¸ºå¯é€‰æ’ä»¶ï¼Œä¸ä¿®æ”¹æ ¸å¿ƒ prompt æ¨¡æ¿
2. **ä½ç½®å›ºå®š**ï¼šé€šè¿‡ `ContextManager.build_messages()` ä¿è¯ sections é¡ºåºä¸€è‡´
3. **æŒ‰éœ€æ³¨å…¥**ï¼šåªæœ‰å¬å›åˆ°ç›¸å…³è®°å¿†æ—¶æ‰æ³¨å…¥ï¼Œé¿å…ç©ºç™½å ä½

### é›†æˆæ•°æ®æµ

```mermaid
graph TB
subgraph "Agent Loop"
  INPUT[ç”¨æˆ·è¾“å…¥] --> PREPARE
  subgraph "Memory Integration"
    PREPARE[prepare_context] --> RECALL
    RECALL[recall memories] --> FORMAT
    FORMAT[æ ¼å¼åŒ–è®°å¿†] --> INJECT
  end
  INJECT --> SYSTEM[System Prompt]
  SYSTEM --> LLM_CALL[LLM è°ƒç”¨]
  LLM_CALL --> RESPONSE[å“åº”ç”Ÿæˆ]
  RESPONSE --> RECORD_U[è®°å½•ç”¨æˆ·æ¶ˆæ¯]
  RECORD_U --> RECORD_A[è®°å½•åŠ©æ‰‹æ¶ˆæ¯]
end
subgraph "Context Window"
  SYSTEM
  USER_MSG[User Message]
  HISTORY[å¯¹è¯å†å²]
end
```

### é›†æˆä»£ç æµç¨‹

```python
# main.py ä¸­çš„é›†æˆé€»è¾‘
async def run_interactive(agent, loop, memory, knowledge):
  while True:
    user_input = get_user_input()
    context_parts = []
    # 1. å¬å›ç›¸å…³è®°å¿†
    if memory:
      memory_context = await memory.prepare_context(user_input)
      if memory_context:
        context_parts.append(memory_context)
    # 2. å¬å›ç›¸å…³çŸ¥è¯†
    if knowledge and knowledge.is_available():
      knowledge_context = await knowledge.get_context_for_query(user_input)
      if knowledge_context:
        context_parts.append(knowledge_context)
    # 3. æ³¨å…¥åˆ° Context
    if context_parts:
      agent.context.set_memory_context("\n\n".join(context_parts))
    # 4. LLM è°ƒç”¨
    response = await loop.run_stream(user_input)
    # 5. æ¸…é™¤è®°å¿†ä¸Šä¸‹æ–‡
    agent.context.clear_memory_context()
    # 6. è®°å½•æœ¬è½®å¯¹è¯
    if memory:
      await memory.record_user_message(user_input)
      await memory.record_assistant_message(response)
    # 7. çŸ¥è¯†æŠ½å–
    if knowledge:
      result = await knowledge.process_message(user_input)
      if result.has_pending_confirmation():
        # æ˜¾ç¤ºç¡®è®¤æç¤º
        for prompt in result.confirmation_prompts:
          print(prompt)
```

### Context æ„å»ºè¿‡ç¨‹

Agent çš„ context é€šè¿‡ `ContextManager.build_messages()` æ–¹æ³•é€æ­¥æ„å»ºï¼š

```mermaid
sequenceDiagram
  participant Agent as Agent
  participant CM as ContextManager
  participant LLM as LLM API
  Note over Agent,CM: 1. åˆå§‹åŒ–é˜¶æ®µ
  Agent->>CM: set_system_prompt(template)
  Note right of CM: æ¸²æŸ“æ¨¡æ¿:<br/>workspace, tools
  Note over Agent,CM: 2. ç”¨æˆ·è¾“å…¥é˜¶æ®µ
  Agent->>CM: set_memory_context(memories + knowledge)
  Note right of CM: æ³¨å…¥å¬å›çš„è®°å¿†å’ŒçŸ¥è¯†
  Note over Agent,CM: 3. æ„å»ºæ¶ˆæ¯é˜¶æ®µ
  Agent->>CM: build_messages()
  CM->>CM: 1. æ·»åŠ  system_prompt
  CM->>CM: 2. æ·»åŠ  memory_context
  CM->>CM: 3. æ·»åŠ  skills_summary
  CM->>CM: 4. æ·»åŠ  loaded_instructions
  CM->>CM: 5. æ·»åŠ  conversation history
  CM-->>Agent: messages[]
  Agent->>LLM: chat(messages)
  Note over Agent,CM: 4. æ¸…ç†é˜¶æ®µ
  Agent->>CM: clear_memory_context()
```

### build_messages() å®ç°é€»è¾‘

```python
def build_messages(self) -> list[dict]:
  """Section order (fixed for agent stability):
  1. System prompt (core instructions, workspace, tools)
  2. Memory context (relevant memories + knowledge)
  3. Skills summary (available skills list)
  4. Loaded skill instructions
  """
  system_content = self._system_prompt
  if self._memory_context:
    system_content += f"\n\n{self._memory_context}"
  skill_summary = self.get_skill_summary()
  if skill_summary:
    system_content += f"\n\n{skill_summary}"
  skill_instructions = self.get_loaded_skill_instructions()
  if skill_instructions:
    system_content += f"\n\n{skill_instructions}"
  messages = [{"role": "system", "content": system_content}]
  for msg in self._messages:
    messages.append(msg.to_openai_format())
  return messages
```

### æœ€ç»ˆ Context ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. System Prompt (é™æ€)               â”‚
â”‚ - Core Behavior Loop                   â”‚
â”‚ - Skill Loading Protocol               â”‚
â”‚ - Guidelines                           â”‚
â”‚ - Workspace & Tools                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Memory Context (åŠ¨æ€æ³¨å…¥)           â”‚
â”‚ ## Relevant Memories                   â”‚
â”‚ 1. [â— E=0.85] ...                      â”‚
â”‚ ## Learned Knowledge                   â”‚
â”‚ - (GPT-4, context_window, 128k)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Skills Summary (åŠ¨æ€)              â”‚
â”‚ - [â—‹] book-flight                     â”‚
â”‚ - [âœ“] codebase-tools                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Loaded Skill Instructions (åŠ¨æ€)   â”‚
â”‚ ### Skill: codebase-tools              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†‘ System Message ç»“æŸ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“ Conversation Messages å¼€å§‹
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Conversation History                â”‚
â”‚ [User]: ä¹‹å‰æˆ‘ä»¬èŠäº†ä»€ä¹ˆï¼Ÿ              â”‚
â”‚ [Assistant]: ...                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Current User Message                â”‚
â”‚ [User]: ç»™æˆ‘è®²è®² PyTorch çš„åŸºç¡€çŸ¥è¯†     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¬å›ç­–ç•¥

### ä¸¤é˜¶æ®µå¬å›ç®—æ³•

```mermaid
graph TB
subgraph "Stage 1: Vector Search"
  Q[æŸ¥è¯¢] --> QV[æŸ¥è¯¢å‘é‡]
  QV --> VS[Milvus ç›¸ä¼¼åº¦æ£€ç´¢]
  VS --> TOP10[Top 10 å€™é€‰]
end
subgraph "Stage 2: Spreading Activation"
  TOP10 --> SEEDS[ç§å­èŠ‚ç‚¹ Top 5]
  SEEDS --> HOP1[Hop 1<br/>decay=0.5]
  HOP1 --> HOP2[Hop 2<br/>decay=0.25]
  HOP2 --> ACTIVATED[æ¿€æ´»èŠ‚ç‚¹é›†åˆ]
end
subgraph "Score Fusion"
  TOP10 --> MERGE
  ACTIVATED --> MERGE[èåˆæ’åº]
  MERGE --> FORMULA["score = 0.7Ã—vec + 0.3Ã—activation"]
  FORMULA --> FINAL[æœ€ç»ˆ Top K]
end
```

### å¬å›é…ç½®å‚æ•°

```python
@dataclass
class MemoryConfig:
  default_recall_limit: int = 10          # é»˜è®¤è¿”å›æ•°é‡
  spreading_activation_hops: int = 2       # ä¼ æ’­è·³æ•°
  spreading_decay_factor: float = 0.5     # æ¯è·³è¡°å‡ç³»æ•°
```

### å¬å›å†…å®¹æ ¼å¼

```markdown
## Relevant Memories
1. [â— E=0.85] ç”¨æˆ·ä¹‹å‰æåˆ°æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œç‰¹åˆ«å¯¹æ·±åº¦å­¦ä¹ æ„Ÿå…´è¶£...
Entities: æœºå™¨å­¦ä¹ , æ·±åº¦å­¦ä¹ , PyTorch
2. [â—‹ E=0.62] æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ...
Entities: æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œ, åå‘ä¼ æ’­
3. [â—Œ E=0.41] PyTorch æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶...
Entities: PyTorch, TensorFlow, æ¡†æ¶
```

**èƒ½é‡æŒ‡ç¤ºå™¨**ï¼š
- `â—` = é«˜èƒ½é‡ (energy > 0.7)
- `â—‹` = ä¸­èƒ½é‡ (0.3 < energy â‰¤ 0.7)
- `â—Œ` = ä½èƒ½é‡ (energy â‰¤ 0.3)

---

## èƒ½é‡è¡°å‡æœºåˆ¶

### è¡°å‡ä¸å¢å¼º

```mermaid
graph LR
subgraph "Energy Dynamics"
  DECAY[æ—¶é—´è¡°å‡<br/>E = Eâ‚€ Ã— e^(-Î»Î”t)]
  BOOST[è®¿é—®å¢å¼º<br/>E += 0.1]
  FEEDBACK[åé¦ˆè°ƒèŠ‚<br/>E += feedback Ã— 0.1]
end
TIME[æ—¶é—´æµé€] --> DECAY
ACCESS[è¢«å¬å›/è®¿é—®] --> BOOST
USER[ç”¨æˆ·åé¦ˆ] --> FEEDBACK
```

### èƒ½é‡é˜ˆå€¼ä¸è¡Œä¸º

| èƒ½é‡èŒƒå›´ | çŠ¶æ€ | ç³»ç»Ÿè¡Œä¸º |
|----------|------|----------|
| `â‰¥ 0.7` | çƒ­è®°å¿† | å¯å‡çº§åˆ° L1 |
| `0.5 ~ 0.7` | æ¸©è®°å¿† | ä¿æŒåœ¨ L1 æˆ– L2 |
| `0.3 ~ 0.5` | å†·è®°å¿† | å¯èƒ½ä» L1 é™çº§ |
| `< 0.3` | é—å¿˜è¾¹ç¼˜ | ä» L1 é©±é€åˆ° L2 |
| `< 0.1` | æ¿’ä¸´é—å¿˜ | å¯èƒ½è¢«æ¸…ç† |

---

## çŸ¥è¯†å­¦ä¹ ç³»ç»Ÿ (Knowledge Learning)

BIEM è®°å¿†ç³»ç»Ÿçš„æ‰©å±•æ¨¡å—ï¼Œä»å¯¹è¯ä¸­æŠ½å–ç»“æ„åŒ–çŸ¥è¯†ä¸‰å…ƒç»„ï¼Œæ”¯æŒçŸ¥è¯†æ›´æ–°å’Œå†²çªæ£€æµ‹ã€‚

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ğŸŒ å…¨å±€å…±äº«** | çŸ¥è¯†åº“åœ¨æ‰€æœ‰ç”¨æˆ·ä¹‹é—´å…±äº«ï¼Œå½¢æˆé›†ä½“çŸ¥è¯†å›¾è°± |
| **ğŸš« ä¸¥æ ¼è¿‡æ»¤** | åªæŠ½å–å®¢è§‚äº‹å®ï¼Œæ‹’ç»ç”¨æˆ·ä¸ªäººä¿¡æ¯ |
| **ğŸ”— ç°‡æ‰©æ•£å¬å›** | è¯­ä¹‰æ£€ç´¢åæ‰©æ•£åˆ°ç›¸å…³çŸ¥è¯†ç°‡ |
| **ğŸ¤– Agent è´¡çŒ®** | Agent ä¹Ÿå¯ä»è‡ªå·±çš„å›å¤ä¸­æå–çŸ¥è¯† |

### çŸ¥è¯†æŠ½å–åŸåˆ™

**âœ… åº”è¯¥æŠ½å–çš„çŸ¥è¯†**ï¼š
- å®¢è§‚äº‹å®ï¼š`(Python, created_by, Guido van Rossum)`
- æŠ€æœ¯æ¦‚å¿µï¼š`(Machine Learning, is_subset_of, Artificial Intelligence)`
- æµç¨‹æè¿°ï¼š`(Gradient Descent, used_for, Neural Network Training)`

**âŒ ä¸åº”è¯¥æŠ½å–çš„çŸ¥è¯†**ï¼š
- ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š~~`(user, age, 25)`~~
- ç”¨æˆ·åå¥½ï¼š~~`(user, prefers, dark_mode)`~~
- ç”¨æˆ·ä½ç½®ï¼š~~`(user, lives_in, Beijing)`~~
- ä¸»è§‚è§‚ç‚¹ï¼š~~`(user, thinks, Python is better)`~~

### ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
subgraph "å¯¹è¯è¾“å…¥"
  USER[ç”¨æˆ·æ¶ˆæ¯] --> PLUGIN[KnowledgeLearningPlugin]
  AGENT[Agent å›å¤] --> PLUGIN
end
subgraph "çŸ¥è¯†æŠ½å– (Strict)"
  PLUGIN --> EXTRACT[KnowledgeExtractor<br/>LLM é©±åŠ¨]
  EXTRACT -->|JSON| FILTER[ä¸¥æ ¼è¿‡æ»¤å™¨]
  FILTER -->|è¿‡æ»¤ç”¨æˆ·ä¿¡æ¯| TRIPLES[ä¸‰å…ƒç»„åˆ—è¡¨]
end
subgraph "å†²çªæ£€æµ‹ (Global)"
  TRIPLES --> CONFLICT[ConflictDetector]
  CONFLICT -->|æ— å†²çª| STORE[ç›´æ¥å­˜å‚¨]
  CONFLICT -->|æœ‰å†²çª| CONFIRM[ConfirmationManager]
  CONFIRM -->|ç”¨æˆ·ç¡®è®¤| UPDATE[æ›´æ–°çŸ¥è¯†]
  CONFIRM -->|ç”¨æˆ·æ‹’ç»| KEEP[ä¿ç•™åŸçŸ¥è¯†]
end
subgraph "å­˜å‚¨å±‚ (Global ğŸŒ)"
  STORE --> PG[(PostgreSQL<br/>knowledge_triples<br/>UNIQUE subject,predicate)]
  UPDATE --> PG
  STORE --> MV[(Milvus<br/>å‘é‡ç´¢å¼•)]
  PG --> HISTORY[(knowledge_history<br/>ç‰ˆæœ¬å†å²)]
end
style EXTRACT fill:#ff6188,color:#fff
style FILTER fill:#ffd93d,color:#333
style PG fill:#a8e6cf,color:#333
style MV fill:#a8e6cf,color:#333
```

### çŸ¥è¯†ä¸‰å…ƒç»„ (KnowledgeTriple)

çŸ¥è¯†ä»¥ `(Subject, Predicate, Object)` ä¸‰å…ƒç»„å½¢å¼å­˜å‚¨ï¼š

```python
@dataclass
class KnowledgeTriple:
  id: str                     # UUID
  subject: str                # ä¸»ä½“: "GPT-4", "Python" (ä¸å…è®¸ "user")
  predicate: str              # å…³ç³»: "context_window", "created_by"
  object: str                 # å®¢ä½“: "128k tokens", "Guido"
  confidence: float = 0.8     # ç½®ä¿¡åº¦ 0.0~1.0
  source: KnowledgeSource     # æ¥æºç±»å‹
  version: int = 1            # ç‰ˆæœ¬å· (æ›´æ–°æ—¶é€’å¢)
  previous_values: list[str]  # å†å²å€¼
  session_id: str             # åˆ›å»º Session
  user_id: str                # è´¡çŒ®è€… ID (å½’å› ï¼Œééš”ç¦»)
  created_at: float           # åˆ›å»ºæ—¶é—´æˆ³
  updated_at: float           # æ›´æ–°æ—¶é—´æˆ³
  vector: list[float]         # å‘é‡åµŒå…¥ (è¯­ä¹‰æ£€ç´¢)
```

**å…¨å±€å”¯ä¸€çº¦æŸ**ï¼š`UNIQUE(subject, predicate)` â€” åŒä¸€ä¸»ä½“çš„åŒä¸€å…³ç³»åªæœ‰ä¸€ä¸ªå€¼

| Subject | Predicate | Object |
|---------|-----------|--------|
| GPT-4 | context_window | 128k tokens |
| Python | created_by | Guido van Rossum |
| Claude 3.5 | max_output | 8k tokens |

**ç¦æ­¢çš„ Subject**ï¼š
- `user` â€” ä¸å…è®¸ä»¥ç”¨æˆ·ä¸ºä¸»ä½“çš„ä¸‰å…ƒç»„
- ä»»ä½•ä¸ªäººä¿¡æ¯ç›¸å…³çš„ä¸»ä½“

### çŸ¥è¯†æ„å›¾ (KnowledgeIntent)

```python
class KnowledgeIntent(str, Enum):
  STATEMENT = "statement"     # æ­£å¸¸äº‹å®é™ˆè¿°
  CORRECTION = "correction"   # çº æ­£ä¹‹å‰çš„ä¿¡æ¯
  QUESTION = "question"       # è¯¢é—®æŸçŸ¥è¯†
  OPINION = "opinion"         # ä¸»è§‚è§‚ç‚¹ (ä¸å­˜å‚¨)
```

### çŸ¥è¯†æ¥æº (KnowledgeSource)

```python
class KnowledgeSource(str, Enum):
  CONVERSATION = "conversation"       # å¯¹è¯ä¸­æå–
  USER_STATED = "user_stated"         # ç”¨æˆ·æ˜ç¡®é™ˆè¿°
  USER_CORRECTION = "user_correction" # ç”¨æˆ·çº æ­£
  USER_VERIFIED = "user_verified"     # ç”¨æˆ·ç¡®è®¤æ›´æ–°
  AGENT_INFERRED = "agent_inferred"   # Agent ä»å›å¤/æœç´¢ç»“æœä¸­æ¨æ–­
```

**Agent çŸ¥è¯†è´¡çŒ®**ï¼šAgent åœ¨å›ç­”é—®é¢˜æ—¶ï¼ˆå¦‚é€šè¿‡ç½‘ç»œæœç´¢è·å–ä¿¡æ¯ï¼‰ï¼Œä¹Ÿä¼šä»è‡ªå·±çš„å›å¤ä¸­æŠ½å–çŸ¥è¯†å¹¶å­˜å…¥å…¨å±€çŸ¥è¯†åº“ã€‚

### æŠ½å–ç»“æœ (ExtractionResult)

```python
@dataclass
class ExtractionResult:
  is_factual: bool = False        # æ˜¯å¦åŒ…å«äº‹å®å†…å®¹
  intent: KnowledgeIntent         # ç”¨æˆ·æ„å›¾
  triples: list[KnowledgeTriple]  # æŠ½å–çš„ä¸‰å…ƒç»„
  confidence: float = 0.0         # æŠ½å–ç½®ä¿¡åº¦
  raw_message: str = ""           # åŸå§‹æ¶ˆæ¯
```

### å†²çªç»“æœ (ConflictResult)

```python
@dataclass
class ConflictResult:
  has_conflict: bool = False
  existing_triple: KnowledgeTriple | None = None
  new_triple: KnowledgeTriple | None = None
  conflict_type: str = ""         # "value_change", "contradiction"
  suggestion: str = ""            # äººç±»å¯è¯»å»ºè®®
```

### å¾…ç¡®è®¤æ›´æ–° (PendingUpdate)

```python
@dataclass
class PendingUpdate:
  id: str
  new_triple: KnowledgeTriple
  existing_triple: KnowledgeTriple | None
  confirmation_message: str
  expires_at: float  # 5åˆ†é’Ÿè¶…æ—¶
```

### çŸ¥è¯†æŠ½å–æµç¨‹

```mermaid
sequenceDiagram
  participant User as ç”¨æˆ·
  participant Plugin as KnowledgeLearningPlugin
  participant Extractor as KnowledgeExtractor
  participant LLM as LLM
  participant Detector as ConflictDetector
  participant Store as KnowledgeStore
  User->>Plugin: "Claude 3.5 Sonnet çš„ä¸Šä¸‹æ–‡æ˜¯ 200k"
  Plugin->>Extractor: extract(message)
  Extractor->>LLM: åˆ†ææ¶ˆæ¯ï¼ŒæŠ½å–ä¸‰å…ƒç»„
  LLM-->>Extractor: {is_factual: true, triples: [...]}
  Extractor-->>Plugin: ExtractionResult
  Plugin->>Detector: check(triple)
  Detector->>Store: find_potential_conflicts()
  alt æ— å†²çª
    Store-->>Detector: []
    Detector-->>Plugin: ConflictResult(has_conflict=false)
    Plugin->>Store: store(triple)
    Plugin-->>User: ğŸ“š Learned 1 new fact(s)
  else æœ‰å†²çª
    Store-->>Detector: [existing_triple]
    Detector-->>Plugin: ConflictResult(has_conflict=true)
    Plugin-->>User: â“ æˆ‘è®°å¾—æ˜¯ Xï¼Œç¡®è®¤æ›´æ–°ä¸º Y å—ï¼Ÿ
  end
```

### å†²çªç¡®è®¤æµç¨‹

å½“æ£€æµ‹åˆ°æ–°çŸ¥è¯†ä¸å·²æœ‰çŸ¥è¯†å†²çªæ—¶ï¼š

```
Session 1:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç”¨æˆ·: GPT-4 çš„ä¸Šä¸‹æ–‡çª—å£æ˜¯ 32k
Agent: ğŸ“š Learned 1 new fact(s)
[å­˜å‚¨: (GPT-4, context_window, 32k)]

Session 2:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç”¨æˆ·: å…¶å® GPT-4 ç°åœ¨æ”¯æŒ 128k äº†
Agent: â“ æˆ‘è®°å¾— GPT-4 çš„ context window æ˜¯ 32k tokensï¼Œ
      æ‚¨ç¡®è®¤æ›´æ–°ä¸º 128k äº†å—ï¼Ÿ
ç”¨æˆ·: æ˜¯çš„
Agent: å¥½çš„ï¼ŒçŸ¥è¯†å·²æ›´æ–°ï¼
[æ›´æ–°: (GPT-4, context_window, 128k), version=2]
```

### è·¨ Session çŸ¥è¯†å¬å›

çŸ¥è¯†åœ¨æ–° Session ä¸­è‡ªåŠ¨æ³¨å…¥ç›¸å…³ä¸Šä¸‹æ–‡ï¼š

```mermaid
graph LR
subgraph "æ–° Session"
  Q[ç”¨æˆ·: ç¥ç»ç½‘ç»œæ€ä¹ˆè®­ç»ƒ?] --> SEARCH
end
subgraph "çŸ¥è¯†æ£€ç´¢"
  SEARCH[è¯­ä¹‰æœç´¢] --> PG[(PostgreSQL)]
  SEARCH --> MV[(Milvus)]
  PG --> RESULTS[ç›¸å…³ä¸‰å…ƒç»„]
  MV --> RESULTS
end
subgraph "Context æ³¨å…¥"
  RESULTS --> FORMAT[æ ¼å¼åŒ–]
  FORMAT --> INJECT["## Learned Knowledge<br/>- (GPT-4, context_window, 128k)"]
end
```

### ç°‡æ‰©æ•£å¬å› (Cluster Expansion)

çŸ¥è¯†æ£€ç´¢æ”¯æŒ"ç°‡æ‰©æ•£"æœºåˆ¶ï¼Œåœ¨åˆå§‹è¯­ä¹‰åŒ¹é…åï¼Œæ‰©å±•åˆ°ç›¸å…³çŸ¥è¯†ç°‡ï¼š

```mermaid
graph TB
subgraph "Stage 1: åˆå§‹æ£€ç´¢"
  QUERY[æŸ¥è¯¢å‘é‡] --> SEARCH[Milvus å‘é‡æœç´¢]
  SEARCH --> TOP_K[Top K ç»“æœ]
end
subgraph "Stage 2: ç°‡æ‰©æ•£"
  TOP_K --> EXPAND[å¯¹æ¯ä¸ªç»“æœæ‰©å±•æœç´¢]
  EXPAND --> CLUSTER1[ç›¸å…³ç°‡ 1]
  EXPAND --> CLUSTER2[ç›¸å…³ç°‡ 2]
  EXPAND --> CLUSTER3[ç›¸å…³ç°‡ 3]
end
subgraph "èåˆæ’åº"
  TOP_K --> MERGE[åˆå¹¶å»é‡]
  CLUSTER1 --> MERGE
  CLUSTER2 --> MERGE
  CLUSTER3 --> MERGE
  MERGE --> FINAL[æœ€ç»ˆç»“æœ<br/>æŒ‰ç»¼åˆåˆ†æ•°æ’åº]
end
style TOP_K fill:#4ecdc4,color:#fff
style CLUSTER1 fill:#a8e6cf,color:#333
style CLUSTER2 fill:#a8e6cf,color:#333
style CLUSTER3 fill:#a8e6cf,color:#333
```

**æ‰©æ•£ç®—æ³•**ï¼š
```python
async def search_with_cluster_expansion(
    query: str,
    top_k: int = 5,           # åˆå§‹æ£€ç´¢æ•°é‡
    expansion_k: int = 3,      # æ¯ä¸ªç»“æœæ‰©å±•æ•°é‡
    min_score: float = 0.5,    # åˆå§‹ç»“æœæœ€ä½åˆ†æ•°
    expansion_min_score: float = 0.4  # æ‰©å±•ç»“æœæœ€ä½åˆ†æ•°
) -> list[tuple[str, float]]:
    # 1. åˆå§‹å‘é‡æ£€ç´¢
    initial_results = vector_search(query, top_k)
    
    # 2. å¯¹æ¯ä¸ªåˆå§‹ç»“æœè¿›è¡Œæ‰©å±•æœç´¢
    for result in initial_results:
        cluster_results = vector_search(result.vector, expansion_k)
        # æ‰©å±•ç»“æœæƒé‡é™ä½ (Ã— 0.7)
        merge_with_lower_weight(cluster_results)
    
    # 3. å»é‡å¹¶æŒ‰ç»¼åˆåˆ†æ•°æ’åº
    return deduplicate_and_sort()
```

**æ•ˆæœ**ï¼šæŸ¥è¯¢"ç¥ç»ç½‘ç»œ"æ—¶ï¼Œä¸ä»…è¿”å›ç›´æ¥ç›¸å…³çš„çŸ¥è¯†ï¼Œè¿˜ä¼šæ‰©æ•£åˆ°"åå‘ä¼ æ’­"ã€"æ¢¯åº¦ä¸‹é™"ã€"æ¿€æ´»å‡½æ•°"ç­‰ç›¸å…³çŸ¥è¯†ç°‡ã€‚

### æ•°æ®åº“ Schema

```sql
-- çŸ¥è¯†ä¸‰å…ƒç»„è¡¨ (å…¨å±€å…±äº«)
CREATE TABLE knowledge_triples (
  id UUID PRIMARY KEY,
  subject VARCHAR(255) NOT NULL,
  predicate VARCHAR(255) NOT NULL,
  object TEXT NOT NULL,
  confidence FLOAT DEFAULT 0.8,
  source VARCHAR(32) DEFAULT 'conversation',
  version INT DEFAULT 1,
  previous_values JSONB DEFAULT '[]',
  user_id VARCHAR(64) DEFAULT '',     -- è´¡çŒ®è€… ID (å½’å› ï¼Œééš”ç¦»)
  session_id VARCHAR(64) DEFAULT '',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- å…¨å±€å”¯ä¸€çº¦æŸ (ä¸æŒ‰ç”¨æˆ·éš”ç¦»)
  UNIQUE(subject, predicate)
);

CREATE INDEX idx_triples_subject ON knowledge_triples(subject);
CREATE INDEX idx_triples_predicate ON knowledge_triples(predicate);

-- çŸ¥è¯†æ›´æ–°å†å²è¡¨
CREATE TABLE knowledge_history (
  id UUID PRIMARY KEY,
  triple_id UUID REFERENCES knowledge_triples(id) ON DELETE CASCADE,
  old_value TEXT,
  new_value TEXT,
  reason VARCHAR(64),
  confirmed BOOLEAN DEFAULT false,
  session_id VARCHAR(64) DEFAULT '',
  contributor_id VARCHAR(64) DEFAULT '',  -- è´¡çŒ®è€…
  timestamp TIMESTAMPTZ DEFAULT NOW()
);
```

**å…³é”®è®¾è®¡**ï¼š
- `UNIQUE(subject, predicate)` è€Œé `UNIQUE(user_id, subject, predicate)`
- çŸ¥è¯†æ˜¯å…¨å±€çš„ï¼Œä»»ä½•ç”¨æˆ·éƒ½å¯ä»¥æ›´æ–°åŒä¸€ä¸ªä¸‰å…ƒç»„
- `user_id` ä»…ç”¨äºè¿½è¸ªè°è´¡çŒ®äº†è¿™æ¡çŸ¥è¯†

### ä¸ Memory Context çš„èåˆ

çŸ¥è¯†ä¸Šä¸‹æ–‡ä¸è®°å¿†ä¸Šä¸‹æ–‡åˆå¹¶æ³¨å…¥ï¼š

```python
# main.py é›†æˆé€»è¾‘
context_parts = []

# è®°å¿†ä¸Šä¸‹æ–‡ (Per-User)
if memory:
  memory_context = await memory.prepare_context(user_input)
  if memory_context:
    context_parts.append(memory_context)

# çŸ¥è¯†ä¸Šä¸‹æ–‡ (Global, ä½¿ç”¨ç°‡æ‰©æ•£)
if knowledge and knowledge.is_available():
  knowledge_context = await knowledge.get_context_for_query(user_input)
  if knowledge_context:
    context_parts.append(knowledge_context)

agent.context.set_memory_context("\n\n".join(context_parts))

# Agent å›å¤åï¼Œä¹Ÿä»å›å¤ä¸­æŠ½å–çŸ¥è¯†
if knowledge:
  await knowledge.process_message(user_input, role="user")
  await knowledge.process_message(response, role="assistant")
```

**æœ€ç»ˆæ³¨å…¥æ ¼å¼**ï¼š

```markdown
## Relevant Memories (ğŸ‘¤ Per-User)
1. [â— E=0.85] ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ...
Entities: æœºå™¨å­¦ä¹ , PyTorch

## Learned Knowledge (ğŸŒ Global)
- (GPT-4, context_window, 128k tokens) [user_verified]
- (Claude 3.5, max_output, 8k tokens) [user_stated]
- (Gradient Descent, used_for, Neural Network Training) [agent_inferred]
```

### é…ç½®å‚æ•°

```python
@dataclass
class KnowledgePluginConfig:
  store_config: KnowledgeStoreConfig    # PostgreSQL é…ç½®
  vector_config: KnowledgeVectorConfig  # Milvus é…ç½®
  extractor_config: ExtractorConfig     # LLM æŠ½å–é…ç½®
  conflict_config: ConflictConfig       # å†²çªæ£€æµ‹é…ç½®
  auto_store: bool = True               # è‡ªåŠ¨å­˜å‚¨æ— å†²çªçŸ¥è¯†
  extract_from_agent: bool = True       # ä» Agent æ¶ˆæ¯æŠ½å–çŸ¥è¯†
  max_context_items: int = 10           # Context ä¸­æœ€å¤§çŸ¥è¯†æ¡æ•°
  enable_vector_search: bool = True     # å¯ç”¨å‘é‡è¯­ä¹‰æœç´¢
  enable_cluster_expansion: bool = True # å¯ç”¨ç°‡æ‰©æ•£å¬å›
  user_id: str = ""                     # è´¡çŒ®è€… ID (å½’å› ï¼Œééš”ç¦»)
  session_id: str = ""                  # Session ID
```

### ä¸¥æ ¼æŠ½å–è¿‡æ»¤å™¨

```python
# ç¦æ­¢çš„è°“è¯åˆ—è¡¨ (ç”¨æˆ·ä¸ªäººä¿¡æ¯)
USER_SPECIFIC_PREDICATES = frozenset({
    "name", "age", "birthday", "birth_date",
    "location", "address", "city", "country",
    "email", "phone", "phone_number",
    "job", "workplace", "employer", "occupation",
    "preference", "ui_preference", "editor",
    "favorite", "likes", "dislikes",
    "hobby", "hobbies", "interest", "interests",
    "goal", "goals", "project", "current_project", "working_on",
})

# è¿‡æ»¤é€»è¾‘
def filter_triple(triple: KnowledgeTriple) -> bool:
    # æ‹’ç» subject == "user"
    if triple.subject.lower() == "user":
        return False
    # æ‹’ç»ç”¨æˆ·ç›¸å…³è°“è¯
    if triple.predicate.lower() in USER_SPECIFIC_PREDICATES:
        return False
    return True
```

---

## é™„å½•ï¼šé…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡

```bash
# Milvus é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=biem_memories      # è®°å¿†å‘é‡é›†åˆ (per-user)
MILVUS_USE_LITE=false
# çŸ¥è¯†å‘é‡é›†åˆåé»˜è®¤ä¸º biem_knowledge (global)

# PostgreSQL é…ç½®
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=biem
POSTGRES_USER=your_user
POSTGRES_PASSWORD=

# è®°å¿†ç³»ç»Ÿå¼€å…³
DISABLE_MEMORY=false

# çŸ¥è¯†å­¦ä¹ å¼€å…³
DISABLE_KNOWLEDGE=false
KNOWLEDGE_VECTOR_SEARCH=true
KNOWLEDGE_CLUSTER_EXPANSION=true    # å¯ç”¨ç°‡æ‰©æ•£

# ç”¨æˆ·é…ç½®
USER_ID=default                     # åˆå§‹ç”¨æˆ· ID (è®°å¿†éš”ç¦»ç”¨)
```

### å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨ Milvus (Docker)
docker compose -f docker-compose.milvus.yml up -d
# å¯åŠ¨ PostgreSQL (å¦‚æœä½¿ç”¨æœ¬åœ°)
brew services start postgresql@18
# åˆ›å»ºæ•°æ®åº“
psql -U your_user -c "CREATE DATABASE biem;"
# è¿è¡Œ Agent
uv run python main.py
```

### å¯è§†åŒ–ç•Œé¢

```bash
# å¯åŠ¨ Web å¯è§†åŒ– (Monokai Pro ä¸»é¢˜)
uv run uvicorn src.omniemployee.web.app:app --port 8000
# è®¿é—® http://localhost:8000
```

åŠŸèƒ½åŒ…æ‹¬ï¼š

**è®°å¿†é¢æ¿ (Per-User ğŸ‘¤)**ï¼š
- **L1 Working Memory ğŸ‘¤**: å½“å‰ç”¨æˆ·çš„å·¥ä½œè®°å¿†èŠ‚ç‚¹åˆ—è¡¨
- **L2 Vector Storage ğŸ‘¤**: å½“å‰ç”¨æˆ·çš„å‘é‡å­˜å‚¨ç»Ÿè®¡å’ŒèŠ‚ç‚¹é¢„è§ˆ
- **L2 Graph ğŸ‘¤**: D3.js åŠ›å¯¼å‘å›¾å¯è§†åŒ–å½“å‰ç”¨æˆ·çš„èŠ‚ç‚¹å…³è”
- **L3 Facts/Links ğŸ‘¤**: å½“å‰ç”¨æˆ·çš„ PostgreSQL æŒä¹…åŒ–æ•°æ®

**çŸ¥è¯†é¢æ¿ (Global ğŸŒ)**ï¼š
- **Knowledge ğŸŒ**: å…¨å±€å…±äº«çš„çŸ¥è¯†ä¸‰å…ƒç»„åˆ—è¡¨

**ç”¨æˆ·ç®¡ç†**ï¼š
- é¡¶éƒ¨ä¸‹æ‹‰æ¡†åˆ‡æ¢ç”¨æˆ·
- åˆ›å»ºæ–°ç”¨æˆ·æŒ‰é’®
- åˆ‡æ¢ç”¨æˆ·åï¼Œè®°å¿†æ•°æ®è‡ªåŠ¨åˆ‡æ¢ï¼ŒçŸ¥è¯†æ•°æ®ä¿æŒä¸å˜

### GUI å®¢æˆ·ç«¯

```bash
# å¯åŠ¨ GPUI åŸç”Ÿå®¢æˆ·ç«¯
cd gui && cargo run --release
```

åŠŸèƒ½åŒ…æ‹¬ï¼š
- å®æ—¶æµå¼å¯¹è¯
- ç”¨æˆ·åˆ‡æ¢ï¼ˆå¤´éƒ¨ä¸‹æ‹‰é€‰æ‹©å™¨ï¼‰
- ä¾§è¾¹æ æ˜¾ç¤º Memory ğŸ‘¤ å’Œ Knowledge ğŸŒ
- å·¥å…·è°ƒç”¨å®æ—¶å±•ç¤º

### æ•°æ®åº“é‡ç½®è„šæœ¬

å½“éœ€è¦æ¸…ç©ºæ•°æ®æˆ–æ›´æ–° Schema æ—¶ï¼š

```bash
# é‡ç½® Milvus å’Œ PostgreSQL
uv run python scripts/reset_databases.py
```

è¯¥è„šæœ¬ä¼šï¼š
1. åˆ é™¤å¹¶é‡å»º Milvus collectionsï¼š
   - `biem_memories` (è®°å¿†å‘é‡ï¼Œå« `user_id`)
   - `biem_knowledge` (çŸ¥è¯†å‘é‡ï¼Œå…¨å±€)
2. åˆ é™¤å¹¶é‡å»º PostgreSQL è¡¨ï¼š
   - `crystal_facts` (L3 äº‹å®ï¼Œå« `user_id`)
   - `crystal_links` (L3 é“¾æ¥ï¼Œå« `user_id`)
   - `knowledge_triples` (çŸ¥è¯†ä¸‰å…ƒç»„ï¼Œå…¨å±€å”¯ä¸€)
   - `knowledge_history` (æ›´æ–°å†å²)
